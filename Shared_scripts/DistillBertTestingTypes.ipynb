{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "527f860b-9dc7-4432-b953-4dd2f313a7e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-19 12:14:46.310444: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-19 12:14:46.364273: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-19 12:14:47.709181: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import datasets\n",
    "import transformers\n",
    "from GPUtil import showUtilization as gpu_usage\n",
    "from numba import cuda\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "from datasets import load_dataset, Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e2ed76c-21ab-4b17-9e32-fddfaf3ae17a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !watch -n 0.5 nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "989ae130-ed7d-47d8-8dfd-2fda5cf1f685",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.0.1\n",
      "CUDA version: 11.8\n",
      "cuDNN version: 8700\n",
      "Current device: 0\n",
      "Is cuda available: True\n"
     ]
    }
   ],
   "source": [
    "print(f'PyTorch version: {torch.__version__}')  # 1.9.1+cu111\n",
    "print(f'CUDA version: {torch.version.cuda}')  # 11.1\n",
    "print(f'cuDNN version: {torch.backends.cudnn.version()}')  # 8005\n",
    "print(f'Current device: {torch.cuda.current_device()}')  # 0\n",
    "print(f'Is cuda available: {torch.cuda.is_available()}')  # TRUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68f01549-7e94-491f-823d-9c9fa23af798",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers version: 4.37.2\n",
      "Datasets version: 2.14.5\n"
     ]
    }
   ],
   "source": [
    "print(f'Transformers version: {transformers.__version__}')\n",
    "print(f'Datasets version: {datasets.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd5e8609-b918-4727-8551-16fa74ac017f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prevent a warning related to the tokenization process in the transformers library. \n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"False\"\n",
    "# Makes CUDA operations synchronous\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d1b7d84-7d7e-4cb0-bcea-64921f983495",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Apr 19 12:14:59 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090        On  | 00000000:41:00.0 Off |                  N/A |\n",
      "| 32%   55C    P2             216W / 350W |    941MiB / 24576MiB |     41%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 3090        On  | 00000000:61:00.0 Off |                  N/A |\n",
      "| 30%   25C    P8              23W / 350W |      6MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce RTX 3090        On  | 00000000:C1:00.0 Off |                  N/A |\n",
      "| 30%   25C    P8              21W / 350W |      6MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce RTX 3090        On  | 00000000:E1:00.0 Off |                  N/A |\n",
      "| 30%   25C    P8              20W / 350W |      6MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A   1538625      C   python                                      932MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Find the GPU with the least memory usage.\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da3c8113-128b-476f-99b1-2232d8d330dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 41% |  4% |\n",
      "|  1 |  0% |  0% |\n",
      "|  2 |  0% |  0% |\n",
      "|  3 |  0% |  0% |\n",
      "GPU Usage after emptying the cache\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 41% |  4% |\n",
      "|  1 |  0% |  0% |\n",
      "|  2 |  0% |  0% |\n",
      "|  3 |  5% |  1% |\n"
     ]
    }
   ],
   "source": [
    "def free_gpu_cache():\n",
    "    print(\"Initial GPU Usage\")\n",
    "    gpu_usage()                             \n",
    "\n",
    "    # free unreferenced tensors from the GPU memory.\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    cuda.select_device(0)\n",
    "    cuda.close()\n",
    "    cuda.select_device(0)\n",
    "\n",
    "    print(\"GPU Usage after emptying the cache\")\n",
    "    gpu_usage()\n",
    "\n",
    "free_gpu_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a1d08c4-2c1a-44e7-a048-d9a9356fda52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_clean</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>omnilight and spotlight incorrect on x11 editor godot version v40betacustombuild 754552b34 system information ubuntu 20045 lts 64 bit amd ryzen 9 5900x 12core amd dimgreycavefish gpu is amd 6600xt issue description half of the light created by the omnilight and spotlight is lost creating dark areas along the z axis with respect to the local placement of the omnilight or spotlight this line to the dark area does not change with any amount of rotation of the omnilight or spotlight translating the light towards larger absolute valuewise negative numbers on the z axis uniformly moves this line steps to reproduce my build as a matter of avoiding crashes in my large project from earlier alpha builds of godot involves first altering coreobjectmessagequeuecpp and commenting out all the calls to the statistics function this is a function that doesnt actually do anything besides use up memory and report back to the developers compile godot on linux with scons targeteditor cxxflagso3 useltoyes platformlinuxbsd open a new scene as a node3d put in a meshinstance3d load the attached obj file as the mesh then add a material override to the mesh add in some color texture to it add in an omnilight then add in a spotlight make the lights bigger range of 1000 meters turn on shadows move them around above the mesh then see the dark area that forms along the negative z axis with respect to the position of the light hexagonobjectziphttpsgithubcomgodotenginegodotfiles9925471hexagonobjectzip minimal reproduction project no response</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>failing test jest integration testssrcpluginsfilesserverroutesintegrationtests file http api find without filtersa test failed on a tracked branch error unable to read snapshot manifest internal server error xml version10 encodingutf8errorcodeinternalerrorcodemessagewe encountered an internal error please try againmessagedetailsamjxxaviufxaumzh9lckpqpcgg3lqxdmox3aa81kg4a5ilxzeowisalrec8qcdxraq4guu5iw6cvsfgtfq9whjsnvwb0sun2fwmrnts2fk8ljjekqwcve86zqbuwj8cvytiitbsfddetailserror at getartifactspecforsnapshot varlibbuildkiteagentbuildskbn24spota56a6fe843560bb5elastickibanaonmergekibanapackageskbnessrcartifactts15111 at runmicrotasks anonymous at processticksandrejections nodeinternalprocesstaskqueues965 at functiongetsnapshot varlibbuildkiteagentbuildskbn24spota56a6fe843560bb5elastickibanaonmergekibanapackageskbnessrcartifactts19426 at downloadsnapshot varlibbuildkiteagentbuildskbn24spota56a6fe843560bb5elastickibanaonmergekibanapackageskbnessrcinstallinstallsnapshotts4320 at installsnapshot varlibbuildkiteagentbuildskbn24spota56a6fe843560bb5elastickibanaonmergekibanapackageskbnessrcinstallinstallsnapshotts7028 at varlibbuildkiteagentbuildskbn24spota56a6fe843560bb5elastickibanaonmergekibanapackageskbnessrcclusterjs10131 at varlibbuildkiteagentbuildskbn24spota56a6fe843560bb5elastickibanaonmergekibanapackageskbntoolinglogsrctoolinglogts8418 at clusterinstallsnapshot varlibbuildkiteagentbuildskbn24spota56a6fe843560bb5elastickibanaonmergekibanapackageskbnessrcclusterjs10012 at testclusterstart varlibbuildkiteagentbuildskbn24spota56a6fe843560bb5elastickibanaonmergekibanapackageskbntestsrcestestesclusterts22024 at startes varlibbuildkiteagentbuildskbn24spota56a6fe843560bb5elastickibanaonmergekibanapackagescoretesthelperscoretesthelperskbnserversrccreaterootts2687 at setupintegrationenvironment varlibbuildkiteagentbuildskbn24spota56a6fe843560bb5elastickibanaonmergekibanasrcpluginsfilesservertestutilssetupintegrationenvironmentts8520 at objectanonymous varlibbuildkiteagentbuildskbn24spota56a6fe843560bb5elastickibanaonmergekibanasrcpluginsfilesserverroutesintegrationtestsroutestestts2219 first failure ci build mainhttpsbuildkitecomelastickibanaonmergebuilds2847601872f0c28364113ad6e954d8d472f5c kibanacidata failedtesttestclassjest integration testssrcpluginsfilesserverroutesintegrationteststestnamefile http api find without filterstestfailcount1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flaky testtendermintbuffer subject of the issue flakiness with teststestdeploymentstestapppytesttendermintbufferfailingtesttendermintbuffer was detected on merge pull request 1469 from valoryxyzfeatgnosissafeutils 5692httpsgithubcomvaloryxyzopenautonomyactionsruns3327820821jobs5503261015 for 9c71dc092e68de94bd7614fd0fac492185e272fb which failed with connectionrefusederror winerror 10061 no connection could be made because the target machine actively refused it full logs follow 20221026t0952024904515z failures 20221026t0952024905075z testtendermintbufferfailingtesttendermintbuffer 20221026t0952024905467z 20221026t0952024905821z self urllib3connectionhttpconnection object at 20221026t0952024906170z 20221026t0952024906410z def newconnself 20221026t0952024907080z establish a socket connection and set nodelay settings on it 20221026t0952024907462z 20221026t0952024907932z return new socket connection 20221026t0952024908338z 20221026t0952024908736z extrakw 20221026t0952024909259z if selfsourceaddress 20221026t0952024909877z extrakwsourceaddress selfsourceaddress 20221026t0952024910272z 20221026t0952024910710z if selfsocketoptions 20221026t0952024911368z extrakwsocketoptions selfsocketoptions 20221026t0952024911717z 20221026t0952024912073z try 20221026t0952024912444z conn connectioncreateconnection 20221026t0952024913191z selfdnshost selfport selftimeout extrakw 20221026t0952024913744z 20221026t0952024913983z 20221026t0952024914701z toxpy39winlibsitepackagesurllib3connectionpy174 20221026t0952024915249z 20221026t0952024915527z 20221026t0952024915944z address localhost 26657 timeout 5 sourceaddress none 20221026t0952024916332z socketoptions 6 1 1 20221026t0952024916524z 20221026t0952024916784z def createconnection 20221026t0952024917195z address 20221026t0952024917681z timeoutsocketglobaldefaulttimeout 20221026t0952024918177z sourceaddressnone 20221026t0952024918648z socketoptionsnone 20221026t0952024919030z 20221026t0952024919606z connect to address and return the socket object 20221026t0952024919961z 20221026t0952024920909z convenience function connect to address a 2tuple host 20221026t0952024921635z port and return the socket object passing the optional 20221026t0952024922347z timeout parameter will set the timeout on the socket instance 20221026t0952024923074z before attempting to connect if no timeout is supplied the 20221026t0952024923815z global default timeout setting returned by funcsocketgetdefaulttimeout 20221026t0952024924598z is used if sourceaddress is set it must be a tuple of host port 20221026t0952024925364z for the socket to bind as a source address before making the connection 20221026t0952024926143z an host of or port 0 tells the os to use the default 20221026t0952024926587z 20221026t0952024926917z 20221026t0952024927297z host port address 20221026t0952024927784z if hoststartswith 20221026t0952024928461z host hoststrip 20221026t0952024928888z err none 20221026t0952024929227z 20221026t0952024929861z using the value from allowedgaifamily in the context of getaddrinfo lets 20221026t0952024930636z us select whether to work with ipv4 dns records ipv6 records or both 20221026t0952024931398z the original createconnection function always returns all records 20221026t0952024931973z family allowedgaifamily 20221026t0952024932343z 20221026t0952024932653z try 20221026t0952024933127z hostencodeidna 20221026t0952024933601z except unicodeerror 20221026t0952024934117z return sixraisefrom 20221026t0952024935117z locationparseerrorus label empty or too long host none 20221026t0952024935555z 20221026t0952024935884z 20221026t0952024936549z for res in socketgetaddrinfohost port family socketsockstream 20221026t0952024937262z af socktype proto canonname sa res 20221026t0952024937756z sock none 20221026t0952024938111z try 20221026t0952024938804z sock socketsocketaf socktype proto 20221026t0952024939199z 20221026t0952024939975z if provided set socket level options before connecting 20221026t0952024940744z setsocketoptionssock socketoptions 20221026t0952024941084z 20221026t0952024941792z if timeout is not socketglobaldefaulttimeout 20221026t0952024942482z socksettimeouttimeout 20221026t0952024943036z if sourceaddress 20221026t0952024943679z sockbindsourceaddress 20221026t0952024944175z sockconnectsa 20221026t0952024944672z return sock 20221026t0952024945022z 20221026t0952024945524z except socketerror as e 20221026t0952024946000z err e 20221026t0952024946490z if sock is not none 20221026t0952024947040z sockclose 20221026t0952024947577z sock none 20221026t0952024947931z 20221026t0952024948348z if err is not none 20221026t0952024948685z raise err 20221026t0952024948929z 20221026t0952024949375z toxpy39winlibsitepackagesurllib3utilconnectionpy95 20221026t0952024949840z 20221026t0952024950125z 20221026t0952024950549z address localhost 26657 timeout 5 sourceaddress none 20221026t0952024950939z socketoptions 6 1 1 20221026t0952024951133z 20221026t0952024951274z def createconnection 20221026t0952024951709z address 20221026t0952024952167z timeoutsocketglobaldefaulttimeout 20221026t0952024952590z sourceaddressnone 20221026t0952024952942z socketoptionsnone 20221026t0952024953238z 20221026t0952024953738z connect to address and return the socket object 20221026t0952024954066z 20221026t0952024954660z convenience function connect to address a 2tuple host 20221026t0952024955386z port and return the socket object passing the optional 20221026t0952024956097z timeout parameter will set the timeout on the socket instance 20221026t0952024956820z before attempting to connect if no timeout is supplied the 20221026t0952024957605z global default timeout setting returned by funcsocketgetdefaulttimeout 20221026t0952024958376z is used if sourceaddress is set it must be a tuple of host port 20221026t0952024959180z for the socket to bind as a source address before making the connection 20221026t0952024959966z an host of or port 0 tells the os to use the default 20221026t0952024960408z 20221026t0952024960743z 20221026t0952024961171z host port address 20221026t0952024961608z if hoststartswith 20221026t0952024962134z host hoststrip 20221026t0952024962557z err none 20221026t0952024962899z 20221026t0952024963578z using the value from allowedgaifamily in the context of getaddrinfo lets 20221026t0952024964310z us select whether to work with ipv4 dns records ipv6 records or both 20221026t0952024965077z the original createconnection function always returns all records 20221026t0952024965647z family allowedgaifamily 20221026t0952024966022z 20221026t0952024966377z try 20221026t0952024966809z hostencodeidna 20221026t0952024967277z except unicodeerror 20221026t0952024967843z return sixraisefrom 20221026t0952024968700z locationparseerrorus label empty or too long host none 20221026t0952024969125z 20221026t0952024969373z 20221026t0952024969957z for res in socketgetaddrinfohost port family socketsockstream 20221026t0952024970580z af socktype proto canonname sa res 20221026t0952024971010z sock none 20221026t0952024971360z try 20221026t0952024971921z sock socketsocketaf socktype proto 20221026t0952024972272z 20221026t0952024972953z if provided set socket level options before connecting 20221026t0952024973621z setsocketoptionssock socketoptions 20221026t0952024973965z 20221026t0952024974545z if timeout is not socketglobaldefaulttimeout 20221026t0952024975150z socksettimeouttimeout 20221026t0952024975635z if sourceaddress 20221026t0952024976202z sockbindsourceaddress 20221026t0952024976570z sockconnectsa 20221026t0952024977107z e connectionrefusederror winerror 10061 no connection could be made because the target machine actively refused it 20221026t0952024977463z 20221026t0952024977880z toxpy39winlibsitepackagesurllib3utilconnectionpy85 connectionrefusederror</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unable to read logs from sway testswhen running forc test to run inlanguage tests any calls to the log function or log intrinsic will trigger the following error img width1064 altimage srchttpsuserimagesgithubusercontentcom17053076201775061afc81adf5a3c416fa09224fcde02b1edpng to repro build the following lib and run forc test library logbug use stdlogginglog fn myfunc test fn mytest myfunc log1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>failing test execution context functional testsxpacktestfunctionalexecutioncontexttestsbrowser·ts execution context browser apps discover app propagates context for discover propagates to elasticsearch via xopaqueid headera test failed on a tracked branch error timed out waiting for execution context propagates to elasticsearch via xopaqueid header at onfailure retryfortruthyts3913 at retryforsuccess retryforsuccessts5913 at retryfortruthy retryfortruthyts273 at retryservicewaitfor retryts595 at assertlogcontains testutilsts523 at contextanonymous browserts5411 at objectapply wrapfunctionjs7316 first failure ci build mainhttpsbuildkitecomelastickibanaonmergebuilds260670185eec3fe76479a9e83d1ec84ab4e42 kibanacidata failedtesttestclassexecution context functional testsxpacktestfunctionalexecutioncontexttestsbrowser·tstestnameexecution context browser apps discover app propagates context for discover propagates to elasticsearch via xopaqueid headertestfailcount1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interface icons inconsistent security issues please disclose security related issues privately to httpswwwntoporgsupportneedhelp2contactus presubmit checklist check applicable sources for existing issues github issueshttpsgithubcomntopntopngissuesqis3aissuelabel3abug faqshttpswwwntoporgsupportdocumentationfaq environment os name eg ubuntu ubuntu os version eg 1804 2004 architecture eg amd64 ntopng versionrevision eg 51211223 ntopng enterprise l v55220915 what happened interface icons are not shown in same manner imagehttpsuserimagesgithubusercontentcom385497551903714156d6f53b1ae54454989fa367b59dc6d5epng note that n2disk is running for ntap0 and ens20 all interfaces are set to mirrored and mac address identification how did you reproduce it debug information paste debug information below copy the service log from systemctl status ntopng or journalctl u ntopng grab a screenshot from the gui demonstrating the issue provide a pcap when this is required to reproduce the issue please remove sensitiveprivate information from logs and pictures</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>create propactiveintegrationtests module background although we have high test coverage we have no definitive assurance that the new changes work endtoend in other words we are missing a complete endtoend test coverage this means we risk releasing a propactive version that have bugs we didnt catch due to how certain kotlinjavagradle versionsconfigurations behave together indeed one could argue we have a demo project that proves a given version is stable to use with its given versionsconfigurations but that technically does not cover snapshot releases but rather a fixed pointversion in time therefore it would be beneficial to create a integration tests that could potentially allow us to cross test propactive with different kotlin versions prove support for java implementations show support for minimum gradle version and so on requirements must have x cover latest kotlin feature release ie 18x x cover latest java lts ie 17xx will be done under 58 x cover latest major gradle version ie 8xx nice to have x cover minimum gradle supported versions this is covered by gradles compatibility charthttpsdocsgradleorgcurrentuserguidecompatibilityhtml x cover both gradle groovy and gradle kotlin dsl as build script in tests gradle kotlin dsl is a compatible alternative to groovy so covering one or the other for our plugin requirements should be sufficient see gradle interoperabilityhttpsdocsgradleorgcurrentuserguidekotlindslhtmlsecinteroperability x separate ci pipeline to highlight when e2e tests are running and when they fail note this is considered a blocker ie new releases cannot be made until this is complete</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bug test client oom for client config clientrandomlocustinsertdeletesearchfilter is there an existing issue for this x i have searched the existing issues environment markdown milvus version master deployment modestandalone or cluster cluster sdk versioneg pymilvus v200rc2 220dev33 current behavior client oom i guess there are something we should had release httpsargoworkflowszillizccworkflowsqafouramg864xtabworkflownodeidfouramg864x876953450nodepanelviewsummary imagehttpsuserimagesgithubusercontentcom82361606194701640931d1d95fee24b3cb224a61f0ebe71b3png expected behavior client memory keeps stable steps to reproduce markdown configyaml locustrandomperformance collections collectionname sift10w128l2 niper 50000 otherfields float1 buildindex true indextype hnsw indexparam m 8 efconstruction 200 task types type query weight 10 params topk 10 nq 10 searchparam ef 16 filters range range float1 gt collectionsize 05 lt collectionsize 1 type load weight 2 type get weight 5 params idslength 10 type insert weight 1 params niper 1 type delete weight 1 params niper 1 connectionnum 1 clientsnum 20 spawnrate 2 duringtime 84h duringtime 72h milvus log no response anything else no response</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>request for ability to orderfilter test suites andor tests without changes to underlying test code q a phpunit version 700 version designated to restrict listeners php version 7xx installation method composer phar in light of 2477 which would remove the current ability to sneakily i know manipulate test suites within listeners this is an issue to request some alternative means of injecting a class with write access currently this can be provided within test classes however there may be some advantage to doing this indirectly as listeners currently allow to explain my own specific needs a few of us are bringing humbug back to life as a mutation testing framework this involves generating small file changes and running phpunit we run phpunit for every single changepotentially hundreds of times to improve performance we take a number of basic steps described here httpsgithubcomhumbughumbugperformance which can be summarised as 1 only run tests on covered lines 2 eliminate tests not applicable to a line 3 order tests fastestfirst to hopefully reach a failure quickly 4 stop on first failureerrorexception serves no purpose to continue after one technically we only order or filter test suites ill need to double check if that was a limitation of using listeners or of phpunit in general or a limitation in our analysis of code coverage data we do not order individual tests within a parent suite unless the children are themselves suites which would actually be the preferred approach the performance benefits are central to the framework being useful as we are not running all tests all the time hundreds of times tldr one way of summarising this is getting an array of tests which would be multidimensional grouping tests by suite manipulating that array injecting a revised array all while assuming execution order is simply determined by array index it could perhaps be done by exportingimporting a name map where avoiding any deeper write level interference with actual objects is preferable</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>release 438 release candidate 1 ruleset test main release candidate issue 14827 version 438 release candidate rc1 tag httpsgithubcomwazuhwazuhtreev438rc1 previous ruleset test 14615 component tested total coverage rules 1164 4102 2838 decoders 120 165 7273 file passed failed status testssysmonini 3 0 testsproftpdini 7 0 testsfortimailini 6 0 testsdovecotini 15 0 teststestexprnegationini 56 0 testseximini 7 0 testswinapplicationini 0 0 testsgcpini 31 0 testspixini 22 0 testscpanelini 7 0 testssophosini 8 0 testssyslogini 6 0 testscheckpointsmart1ini 18 0 testsnextcloudini 8 0 testsiptablesini 8 0 testssambaini 4 0 testsciscoasaini 88 0 testsdropbearini 3 0 testssystemdini 2 0 testssonicwallini 11 0 testsvsftpdini 4 0 testsfirewalldini 2 0 testsmailscannerini 1 0 testsowlhini 4 0 testsfortiauthini 4 0 testsciscoiosini 17 0 testsvulndetectorini 2 0 testsopenldapini 9 0 testskernelusbini 6 0 testsauditdini 31 0 testsglpiini 3 0 testsf5bigipini 48 0 testsmcafeeepoini 1 0 testsopensmtpdini 7 0 testssudoini 8 0 testsunboundini 0 0 testsnetscreenini 4 0 testsphpini 2 0 testsdoasini 4 0 testspamini 5 0 testsarborini 2 0 testsoffice365ini 128 0 testspaloaltoini 16 0 teststestosregexregexini 28 0 testsfortigateini 45 0 testsossecini 5 0 testswebrulesini 10 0 testsoscapini 32 0 testsexchangeini 2 0 testssquidrulesini 2 0 testsciscoftdini 42 0 testssophosfwini 10 0 testsgithubini 324 0 testspostfixini 2 0 testsauditscpini 8 0 testsapiini 20 0 testsrshini 2 0 testsapparmorini 5 0 testsnginxini 12 0 testsnamedini 5 0 teststestpcre2regexini 33 0 testsfortiddosini 1 0 testsopenvpnldapini 2 0 testscimserverini 2 0 teststestosmatchregexini 6 0 testsfreepbxini 6 0 testsoverwriteini 10 0 testssshdini 48 0 testsjunosini 3 0 testsmodsecurityini 6 0 testspfsenseini 2 0 teststestfeaturesini 5 0 testscloudflarewafini 13 0 testswebappsecini 31 0 testshuaweiusgini 3 0 testssuini 5 0 testsapacheini 12 0 testsgitlabini 27 0 testsawss3accessini 10 0 teststeststaticfiltersini 28 0 testsesetini 8 0 testsfireeyeini 3 0 testspandapapsini 8 0 python runtestspy restarting wazuhmanager file testssonicwallini file testsapacheini file testsapiini file testsapparmorini file testsarborini file testsauditscpini file testsauditdini file testsawss3accessini file testscheckpointsmart1ini file testscimserverini file testsciscoasaini file testsciscoftdini file testsciscoiosini file testscloudflarewafini file testscpanelini file testsdoasini file testsdovecotini file testsdropbearini file testsesetini file testsexchangeini file testseximini file testsf5bigipini file testsfireeyeini file testsfirewalldini file testsfortiauthini file testsfortiddosini file testsfortigateini file testsfortimailini file testsfreepbxini file testsgcpini file testsgithubini file testsgitlabini file testsglpiini file testshuaweiusgini file testsiptablesini file testsjunosini file testskernelusbini file testsmailscannerini file testsmcafeeepoini file testsmodsecurityini file testsnamedini file testsnetscreenini file testsnextcloudini file testsnginxini file testsoffice365ini file testsopenldapini file testsopensmtpdini file testsopenvpnldapini file testsoscapini file testsossecini file testsoverwriteini file testsowlhini file testspaloaltoini file testspamini file testspandapapsini file testspfsenseini file testsphpini file testspixini file testspostfixini file testsproftpdini file testsrshini file testssambaini file testssophosini file testssophosfwini file testssquidrulesini file testssshdini file testssuini file testssudoini file testssyslogini file testssysmonini file testssystemdini file teststestexprnegationini file teststestfeaturesini file teststestosmatchregexini file teststestosregexregexini file teststestpcre2regexini file teststeststaticfiltersini file testsunboundini file testsvsftpdini file testsvulndetectorini file testswebappsecini file testswebrulesini file testswinapplicationini</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2982 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    label\n",
       "text_clean                                               \n",
       "omnilight and spotlight incorrect on x11 editor...      1\n",
       "failing test jest integration testssrcpluginsfi...      1\n",
       "flaky testtendermintbuffer subject of the issue...      1\n",
       "unable to read logs from sway testswhen running...      1\n",
       "failing test execution context functional tests...      1\n",
       "...                                                   ...\n",
       "interface icons inconsistent security issues pl...      2\n",
       "create propactiveintegrationtests module backgr...      2\n",
       "bug test client oom for client config clientran...      2\n",
       "request for ability to orderfilter test suites ...      2\n",
       "release 438 release candidate 1 ruleset test ma...      2\n",
       "\n",
       "[2982 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Final_cleaned_test_types.csv\" , index_col = 0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13a6a7cd-4d14-4bab-83da-6f7d37604a6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Smaller and faster than bert.\n",
    "base_model_id = \"distilbert-base-uncased\"\n",
    "\n",
    "epochs = 5 #Number of full cyles through the training set.\n",
    "num_labels = 2 \n",
    "learning_rate = 5e-5 # Rate the model updates based on the data its trained on.\n",
    "train_batch_size = 16 # Number of training examples in one iteration.\n",
    "eval_batch_size = 32 # Number evalutaion examples in on iteratoion.\n",
    "save_strategy = \"no\" # Should the model be saved automatically during training.\n",
    "save_steps = 500 # How often to save the model during training. No effect since no over.\n",
    "logging_steps = 100\n",
    "model_dir = \"./model\" #Where to save model\n",
    "\n",
    "# Use early stopping to prevent overfitting\n",
    "#load_best_model_at_end=True\n",
    "#metric_for_best_model=\"eval_loss\"\n",
    "#greater_is_better=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "644b3194-eb30-4222-814b-cc3d063cbc6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split dataframe into three parts: training, validation and testing.\n",
    "def train_validate_test_split(df, train_percent=.8, validate_percent=.1, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    # Shuffle index of dataframe\n",
    "    perm = np.random.permutation(df.index)\n",
    "    \n",
    "    df_length = len(df.index)\n",
    "    \n",
    "    # Number of row in training set\n",
    "    train_end = int(train_percent * df_length)\n",
    "    # Number of rows in validate set\n",
    "    validate_end = int(validate_percent * df_length) + train_end\n",
    "    \n",
    "    # From start to train end\n",
    "    train = df.iloc[perm[:train_end]]\n",
    "    # From train_end to validate_end\n",
    "    validate = df.iloc[perm[train_end:validate_end]]\n",
    "    # From validate to the last row in dataframe.\n",
    "    test = df.iloc[perm[validate_end:]]\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4092bcdd-287a-4821-9683-ca3f1907f564",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drops rows with missing values\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9d44b78-2434-459c-b4b8-ca5dce978910",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_clean</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>omnilight and spotlight incorrect on x11 edito...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>failing test jest integration testssrcpluginsf...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>flaky testtendermintbuffer subject of the issu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unable to read logs from sway testswhen runnin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>failing test execution context functional test...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2977</th>\n",
       "      <td>interface icons inconsistent security issues p...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2978</th>\n",
       "      <td>create propactiveintegrationtests module backg...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2979</th>\n",
       "      <td>bug test client oom for client config clientra...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2980</th>\n",
       "      <td>request for ability to orderfilter test suites...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2981</th>\n",
       "      <td>release 438 release candidate 1 ruleset test m...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2982 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_clean  label\n",
       "0     omnilight and spotlight incorrect on x11 edito...      1\n",
       "1     failing test jest integration testssrcpluginsf...      1\n",
       "2     flaky testtendermintbuffer subject of the issu...      1\n",
       "3     unable to read logs from sway testswhen runnin...      1\n",
       "4     failing test execution context functional test...      1\n",
       "...                                                 ...    ...\n",
       "2977  interface icons inconsistent security issues p...      2\n",
       "2978  create propactiveintegrationtests module backg...      2\n",
       "2979  bug test client oom for client config clientra...      2\n",
       "2980  request for ability to orderfilter test suites...      2\n",
       "2981  release 438 release candidate 1 ruleset test m...      2\n",
       "\n",
       "[2982 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resets the index after dropping rows\n",
    "data.reset_index(inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2398a175-37bb-41a9-ab9c-c86b0b890906",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_clean</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>omnilight and spotlight incorrect on x11 edito...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>failing test jest integration testssrcpluginsf...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>flaky testtendermintbuffer subject of the issu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unable to read logs from sway testswhen runnin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>failing test execution context functional test...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2977</th>\n",
       "      <td>interface icons inconsistent security issues p...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2978</th>\n",
       "      <td>create propactiveintegrationtests module backg...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2979</th>\n",
       "      <td>bug test client oom for client config clientra...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2980</th>\n",
       "      <td>request for ability to orderfilter test suites...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2981</th>\n",
       "      <td>release 438 release candidate 1 ruleset test m...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2982 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_clean  label\n",
       "0     omnilight and spotlight incorrect on x11 edito...      1\n",
       "1     failing test jest integration testssrcpluginsf...      1\n",
       "2     flaky testtendermintbuffer subject of the issu...      1\n",
       "3     unable to read logs from sway testswhen runnin...      1\n",
       "4     failing test execution context functional test...      1\n",
       "...                                                 ...    ...\n",
       "2977  interface icons inconsistent security issues p...      2\n",
       "2978  create propactiveintegrationtests module backg...      2\n",
       "2979  bug test client oom for client config clientra...      2\n",
       "2980  request for ability to orderfilter test suites...      2\n",
       "2981  release 438 release candidate 1 ruleset test m...      2\n",
       "\n",
       "[2982 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02787dd7-7866-4243-9bd5-40c661ad1083",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 80% trainig, 10% validate, 10% test. Seed 42.\n",
    "# Test 80-10-10 and 70-15-15\n",
    "train , validate , test = train_validate_test_split(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2de236c-d091-451b-b157-af18a4b9dd4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.set_index(\"label\" , inplace = True)\n",
    "validate.set_index(\"label\" , inplace = True)\n",
    "test.set_index(\"label\" , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b346d9c-1417-466d-9e94-7bd373ba3056",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bugios the spacebar caption doesnt get refresh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>backport v11 bug no resource limits set for th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>merge tests from vaadinflow 90 configure sprin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>add initial e2e testsdescribe the solution you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>corevchanxen v419 r42update of corevchanxen to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>write tests for dexwrite tests for the dex mod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>typescript client test to manage rpc serverfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>additional checks and tests for muteto be cons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>longevity show mv for nexmark queriesq0 q1 q2 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>improve visibility of what forms are linked to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>299 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text_clean\n",
       "label                                                   \n",
       "5      bugios the spacebar caption doesnt get refresh...\n",
       "5      backport v11 bug no resource limits set for th...\n",
       "2      merge tests from vaadinflow 90 configure sprin...\n",
       "5      add initial e2e testsdescribe the solution you...\n",
       "2      corevchanxen v419 r42update of corevchanxen to...\n",
       "...                                                  ...\n",
       "5         write tests for dexwrite tests for the dex mod\n",
       "5      typescript client test to manage rpc serverfor...\n",
       "5      additional checks and tests for muteto be cons...\n",
       "5      longevity show mv for nexmark queriesq0 q1 q2 ...\n",
       "1      improve visibility of what forms are linked to...\n",
       "\n",
       "[299 rows x 1 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2303a1e0-4e3c-4a66-936e-84ee7b73e8a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['text_clean', 'label'],\n",
       "        num_rows: 299\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['text_clean', 'label'],\n",
       "        num_rows: 2385\n",
       "    })\n",
       "    validate: Dataset({\n",
       "        features: ['text_clean', 'label'],\n",
       "        num_rows: 298\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert from Pandas DataFrame to Hugging Face datasets\n",
    "tds = Dataset.from_pandas(train)\n",
    "vds = Dataset.from_pandas(validate)\n",
    "testds = Dataset.from_pandas(test)\n",
    "\n",
    "\n",
    "ds = DatasetDict()\n",
    "\n",
    "ds[\"test\"] = testds\n",
    "ds[\"train\"] = tds\n",
    "ds[\"validate\"] = vds\n",
    "\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "975863f4-f4b2-43cd-941b-83e7486da7d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = ds[\"train\"]\n",
    "valid_dataset = ds[\"validate\"]\n",
    "test_ds = ds[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5bceaba9-3261-4a04-88be-831d51fac6c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text_clean': 'general sanity checks on gamestest for compatibility with database and frontend game actions should be replayable prevent situations where a deserialized object is not the same object as the one in game causing updates on something else replaying actions should generate the same view as when the original action was made store jsonfiles of replays that are tested with assertions of what is to be expected this can also detect for viewchanges or breaking replaychanges no kotlinspecific data sent to frontend data is correctly serializable and deserializable tofrom database use a random amount of players in dslrandomplaytest with a flexible amount of wsclients if these tests take too long time perhaps look into a way to not run them for each jenkinsbuild',\n",
       " 'label': 2}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "054ea27f-3b88-4cb1-b02f-1d12a82ec193",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6de1f9e-9ea1-42d6-b2f6-8448d962abe0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(base_model_id, num_labels=num_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2102ca1b-6573-4b17-bd8b-ab8ebfdf189c",
   "metadata": {},
   "source": [
    "# Tokanization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7b61137-9aff-4b4c-b925-3c612e5ca9e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_ckpt = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d00c290e-d1fb-4d4b-b8a4-7436e69945b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54248470fb8c4f189b613b1572884bab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2385 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "181fd5e1af4e4cf2a9a14af44ba9b5f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/298 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47548fd63dec4fcd98a1f24fa1106699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/299 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Tokenize the dataset to the correct input for the transformer model.\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text_clean\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=True, batch_size=len(train_dataset))\n",
    "valid_dataset = valid_dataset.map(tokenize, batched=True, batch_size=len(valid_dataset))\n",
    "test_dataset = test_ds.map(tokenize, batched=True, batch_size=len(test_ds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62066e28-3e64-4394-8254-5d33205ce273",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=model_dir,\n",
    "    num_train_epochs=epochs,\n",
    "    per_device_train_batch_size=train_batch_size,\n",
    "    per_device_eval_batch_size=eval_batch_size,\n",
    "    save_strategy=save_strategy,\n",
    "    save_steps=save_steps,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=learning_rate,\n",
    "    logging_steps=logging_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f861feb1-3b00-4581-8577-97b41d4a8af5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c188e5b9-0224-4e6b-b935-7d61fd0acf0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2127537172.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[32], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    export CUDA_LAUNCH_BLOCKING=1\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "export CUDA_LAUNCH_BLOCKING=1\n",
    "export TORCH_USE_CUDA_DSA=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8da21617-2244-4441-835a-8fc1ce2b7772",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/dl/lib/python3.10/site-packages/transformers/trainer.py:1539\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1537\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1544\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/dl/lib/python3.10/site-packages/transformers/trainer.py:1549\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1546\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_inner_training_loop\u001b[39m(\n\u001b[1;32m   1547\u001b[0m     \u001b[38;5;28mself\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, args\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, resume_from_checkpoint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, trial\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, ignore_keys_for_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1548\u001b[0m ):\n\u001b[0;32m-> 1549\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfree_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1550\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size \u001b[38;5;241m=\u001b[39m batch_size\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mauto_find_batch_size:\n",
      "File \u001b[0;32m~/.conda/envs/dl/lib/python3.10/site-packages/accelerate/accelerator.py:2986\u001b[0m, in \u001b[0;36mAccelerator.free_memory\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2984\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeepspeed_engine_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2985\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 2986\u001b[0m \u001b[43mrelease_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/dl/lib/python3.10/site-packages/accelerate/utils/memory.py:61\u001b[0m, in \u001b[0;36mrelease_memory\u001b[0;34m(*objects)\u001b[0m\n\u001b[1;32m     59\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnpu\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 61\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m objects\n",
      "File \u001b[0;32m~/.conda/envs/dl/lib/python3.10/site-packages/torch/cuda/memory.py:133\u001b[0m, in \u001b[0;36mempty_cache\u001b[0;34m()\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Releases all unoccupied cached memory currently held by the caching\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03mallocator so that those can be used in other GPU application and visible in\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03m`nvidia-smi`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03m    more details about GPU memory management.\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[0;32m--> 133\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_emptyCache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "trainer.train() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ece97dd-c2f8-4e97-80be-90318c176c46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='706' max='227' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [227/227 5:09:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_result = trainer.evaluate(eval_dataset=valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9d3961b0-680f-4753-a2f8-708c3f408cc0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 5.0\n",
      "\n",
      "eval_accuracy = 0.8631273330568229\n",
      "\n",
      "eval_f1 = [0.86169321 0.86453202]\n",
      "\n",
      "eval_loss = 0.7703143358230591\n",
      "\n",
      "eval_precision = [0.86751055 0.8588907 ]\n",
      "\n",
      "eval_recall = [0.85595337 0.87024793]\n",
      "\n",
      "eval_runtime = 77.027\n",
      "\n",
      "eval_samples_per_second = 93.902\n",
      "\n",
      "eval_steps_per_second = 2.947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, value in sorted(eval_result.items()):\n",
    "    print(f\"{key} = {value}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c384cc8-1b5e-4161-8f0b-230a3d453637",
   "metadata": {},
   "source": [
    "## Training loss decreases, valdiation loss increases = Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b77cc45b-1d9e-47d7-b73a-c56a4ff77ec7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate test data set\n",
    "test_results = trainer.evaluate(eval_dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d57397f6-5a08-4562-824e-642b03d0ce3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 5.0\n",
      "\n",
      "eval_accuracy = 0.8679662657265311\n",
      "\n",
      "eval_f1 = [0.86428876 0.87144972]\n",
      "\n",
      "eval_loss = 0.7561773061752319\n",
      "\n",
      "eval_precision = [0.85686109 0.8786645 ]\n",
      "\n",
      "eval_recall = [0.87184633 0.86435247]\n",
      "\n",
      "eval_runtime = 77.085\n",
      "\n",
      "eval_samples_per_second = 93.832\n",
      "\n",
      "eval_steps_per_second = 2.945\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, value in sorted(test_results.items()):\n",
    "    print(f\"{key} = {value}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73018a46-ce85-4b2c-971f-580c684d2ae3",
   "metadata": {},
   "source": [
    "# Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "90cd7bb6-6c93-478f-bbf0-ba28e6e9f9e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "separate_test_set_results = trainer.evaluate(eval_dataset=separate_test_set_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1b2c9011-0a0b-41a4-9890-f8b572201155",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 5.0\n",
      "\n",
      "eval_accuracy = 0.8667413213885778\n",
      "\n",
      "eval_f1 = [0.86680761 0.86667497]\n",
      "\n",
      "eval_loss = 0.7555153369903564\n",
      "\n",
      "eval_precision = [0.86799502 0.86548981]\n",
      "\n",
      "eval_recall = [0.86562345 0.86786338]\n",
      "\n",
      "eval_runtime = 82.7271\n",
      "\n",
      "eval_samples_per_second = 97.151\n",
      "\n",
      "eval_steps_per_second = 3.046\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, value in sorted(separate_test_set_results.items()):\n",
    "    print(f\"{key} = {value}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "38713ff0-d6c7-4016-a4a8-29a42d65c926",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.save_model(model_dir + \"_local\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "35467216-6f3d-4e00-a836-2d72510cbfb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "    \n",
    "classifier = pipeline(\"text-classification\", model=\"./model_local\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c63e264c-607c-49ba-b283-d623d47fdb04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b2246fcd-713c-40bd-9230-63797d2181a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_1', 'score': 0.8895082473754883}]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"this contain bugs regarding testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d2e0a903-6900-443a-8c80-c45b798026ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.9836528301239014}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"this contain bugs regarding automtion not testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "38318df6-498f-4b6e-983d-4962b18f6179",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_1', 'score': 0.9379398822784424}]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"this bug has super high impact on the project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "25f21621-0738-4306-bdfc-6d18844757e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_clean</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>make sure integration tests are running with i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cover anvil service response in unit testshttp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>service apprepositorycontroller should be cach...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>many caches persist between test casesan examp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>improve friendliness of behat text pattern mat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          text_clean  label\n",
       "0  make sure integration tests are running with i...      1\n",
       "1  cover anvil service response in unit testshttp...      1\n",
       "2  service apprepositorycontroller should be cach...      1\n",
       "3  many caches persist between test casesan examp...      1\n",
       "4  improve friendliness of behat text pattern mat...      1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('clean_test_or_not_test_debt.csv',index_col = 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a7675371-a5c8-4659-aa44-4ce802165e61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def classify_text(text):\n",
    "    # Get prediction\n",
    "    result = classifier(text)\n",
    "    # Return the label of the highest scoring classification\n",
    "    return result[0]['label']\n",
    "\n",
    "# Apply the classification function to your text column (assuming it's named 'text_clean')\n",
    "df['predicted_label'] = df['text_clean'].apply(classify_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cdd65248-d578-4ad8-bc10-eb08a5a78683",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_clean</th>\n",
       "      <th>label</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>make sure integration tests are running with i...</td>\n",
       "      <td>1</td>\n",
       "      <td>LABEL_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cover anvil service response in unit testshttp...</td>\n",
       "      <td>1</td>\n",
       "      <td>LABEL_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>service apprepositorycontroller should be cach...</td>\n",
       "      <td>1</td>\n",
       "      <td>LABEL_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>many caches persist between test casesan examp...</td>\n",
       "      <td>1</td>\n",
       "      <td>LABEL_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>improve friendliness of behat text pattern mat...</td>\n",
       "      <td>1</td>\n",
       "      <td>LABEL_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ci test flake can modify upstreams repeatedly ...</td>\n",
       "      <td>1</td>\n",
       "      <td>LABEL_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>fix broken shebang on smoke test script contin...</td>\n",
       "      <td>1</td>\n",
       "      <td>LABEL_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>add webworkers tests description add unit test...</td>\n",
       "      <td>1</td>\n",
       "      <td>LABEL_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>servlet 60 correct the list of valid orderings...</td>\n",
       "      <td>1</td>\n",
       "      <td>LABEL_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>reevaluating testyml file to remove old instal...</td>\n",
       "      <td>1</td>\n",
       "      <td>LABEL_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           text_clean  label predicted_label\n",
       "0   make sure integration tests are running with i...      1         LABEL_1\n",
       "1   cover anvil service response in unit testshttp...      1         LABEL_1\n",
       "2   service apprepositorycontroller should be cach...      1         LABEL_0\n",
       "3   many caches persist between test casesan examp...      1         LABEL_1\n",
       "4   improve friendliness of behat text pattern mat...      1         LABEL_1\n",
       "..                                                ...    ...             ...\n",
       "95  ci test flake can modify upstreams repeatedly ...      1         LABEL_1\n",
       "96  fix broken shebang on smoke test script contin...      1         LABEL_1\n",
       "97  add webworkers tests description add unit test...      1         LABEL_1\n",
       "98  servlet 60 correct the list of valid orderings...      1         LABEL_0\n",
       "99  reevaluating testyml file to remove old instal...      1         LABEL_1\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b8e9e852-0129-4b53-b322-610754da9814",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_clean</th>\n",
       "      <th>label</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>predicted_label_numeric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>make sure integration tests are running with i...</td>\n",
       "      <td>1</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cover anvil service response in unit testshttp...</td>\n",
       "      <td>1</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>service apprepositorycontroller should be cach...</td>\n",
       "      <td>1</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>many caches persist between test casesan examp...</td>\n",
       "      <td>1</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>improve friendliness of behat text pattern mat...</td>\n",
       "      <td>1</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          text_clean  label predicted_label  \\\n",
       "0  make sure integration tests are running with i...      1         LABEL_1   \n",
       "1  cover anvil service response in unit testshttp...      1         LABEL_1   \n",
       "2  service apprepositorycontroller should be cach...      1         LABEL_0   \n",
       "3  many caches persist between test casesan examp...      1         LABEL_1   \n",
       "4  improve friendliness of behat text pattern mat...      1         LABEL_1   \n",
       "\n",
       "   predicted_label_numeric  \n",
       "0                        1  \n",
       "1                        1  \n",
       "2                        0  \n",
       "3                        1  \n",
       "4                        1  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Assuming your predicted labels are in a format like 'LABEL_0', 'LABEL_1', etc.\n",
    "# Convert these to numeric by extracting the number part and converting it to an integer\n",
    "df['predicted_label_numeric'] = df['predicted_label'].apply(lambda x: int(x.split('_')[1]))\n",
    "\n",
    "# Now, your actual labels are assumed to be in the 'label' column and already numeric\n",
    "actual_labels = df['label']\n",
    "\n",
    "# Predicted labels are now in 'predicted_label_numeric'\n",
    "predicted_labels = df['predicted_label_numeric']\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "77c935dc-270b-47bd-b693-acaa5e57f603",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv('TestNotTestRes.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa24caac-2ca2-45fa-a547-1122d66927d6",
   "metadata": {},
   "source": [
    "### Delete the dataset with large memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c0a94be5-8513-4267-81c7-f67f5d6aa688",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8183673469387756\n",
      "F1 Score: 0.831758034026465\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(actual_labels, predicted_labels)\n",
    "\n",
    "# Calculate F1 score\n",
    "# Assuming it's a binary classification, you could specify the average method if it's multi-class\n",
    "f1 = f1_score(actual_labels, predicted_labels, average='binary' if df['label'].nunique() == 2 else 'weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0ad0df6f-2507-4be1-a026-43145120c661",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6013e6b7-e0f6-4755-a8ab-0eaabdd95c4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ed059002-d156-431c-8556-c7152abe62ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Free cache\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "86114411-d883-48d6-a960-f90726d8ae2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Mar 13 22:13:42 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:01:00.0 Off |                  N/A |\n",
      "| 22%   28C    P8              28W / 250W |  10503MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:23:00.0 Off |                  N/A |\n",
      "| 25%   48C    P2             104W / 250W |   2183MiB / 11264MiB |     30%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:41:00.0 Off |                  N/A |\n",
      "| 28%   50C    P2             139W / 250W |   1029MiB / 11264MiB |     39%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:61:00.0 Off |                  N/A |\n",
      "| 22%   23C    P8              17W / 250W |  10503MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:81:00.0 Off |                  N/A |\n",
      "| 27%   48C    P2             116W / 250W |   1077MiB / 11264MiB |     45%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:A1:00.0 Off |                  N/A |\n",
      "| 26%   46C    P2             184W / 250W |    679MiB / 11264MiB |     32%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:C1:00.0 Off |                  N/A |\n",
      "| 28%   49C    P2             192W / 250W |   1053MiB / 11264MiB |     38%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:E1:00.0 Off |                  N/A |\n",
      "| 22%   35C    P2              66W / 250W |   1627MiB / 11264MiB |     27%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A    257091      C   python                                    10500MiB |\n",
      "|    1   N/A  N/A    368329      C   ...dinger/2023-3/internal/bin/gdesmond      344MiB |\n",
      "|    1   N/A  N/A   1009491      C   ...dinger/2023-3/internal/bin/gdesmond      332MiB |\n",
      "|    1   N/A  N/A   3693822      C   ...ome/nehad/.conda/envs/dl/bin/python     1208MiB |\n",
      "|    1   N/A  N/A   3864033      C   python                                      308MiB |\n",
      "|    2   N/A  N/A   1009246      C   ...dinger/2023-3/internal/bin/gdesmond      344MiB |\n",
      "|    2   N/A  N/A   1009311      C   ...dinger/2023-3/internal/bin/gdesmond      332MiB |\n",
      "|    2   N/A  N/A   1009337      C   ...dinger/2023-3/internal/bin/gdesmond      332MiB |\n",
      "|    3   N/A  N/A   3986009      C   python                                    10500MiB |\n",
      "|    4   N/A  N/A    402788      C   ...dinger/2023-3/internal/bin/gdesmond      332MiB |\n",
      "|    4   N/A  N/A    435202      C   ...dinger/2023-3/internal/bin/gdesmond      362MiB |\n",
      "|    4   N/A  N/A   1969176      C   ...dinger/2023-3/internal/bin/gdesmond      346MiB |\n",
      "|    5   N/A  N/A    426783      C   ...dinger/2023-3/internal/bin/gdesmond      344MiB |\n",
      "|    5   N/A  N/A    432808      C   ...dinger/2023-3/internal/bin/gdesmond      344MiB |\n",
      "|    6   N/A  N/A    394081      C   ...dinger/2023-3/internal/bin/gdesmond      360MiB |\n",
      "|    6   N/A  N/A    464966      C   ...dinger/2023-3/internal/bin/gdesmond      328MiB |\n",
      "|    6   N/A  N/A    480873      C   ...dinger/2023-3/internal/bin/gdesmond      328MiB |\n",
      "|    7   N/A  N/A   2841079      C   ...dinger/2023-3/internal/bin/gdesmond      340MiB |\n",
      "|    7   N/A  N/A   4113297      C   python3                                    1296MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849b32d3-e0b5-4bf2-97cb-cfc68e81c216",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375f6979-dd8b-47ac-8ac8-4b240f86de14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
