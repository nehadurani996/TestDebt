{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "527f860b-9dc7-4432-b953-4dd2f313a7e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-28 00:41:45.624854: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-28 00:41:45.680268: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-28 00:41:48.428455: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import datasets\n",
    "import transformers\n",
    "from GPUtil import showUtilization as gpu_usage\n",
    "from numba import cuda\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "from datasets import load_dataset, Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e2ed76c-21ab-4b17-9e32-fddfaf3ae17a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !watch -n 0.5 nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "989ae130-ed7d-47d8-8dfd-2fda5cf1f685",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.0.1\n",
      "CUDA version: 11.8\n",
      "cuDNN version: 8700\n",
      "Current device: 0\n",
      "Is cuda available: True\n"
     ]
    }
   ],
   "source": [
    "print(f'PyTorch version: {torch.__version__}')  # 1.9.1+cu111\n",
    "print(f'CUDA version: {torch.version.cuda}')  # 11.1\n",
    "print(f'cuDNN version: {torch.backends.cudnn.version()}')  # 8005\n",
    "print(f'Current device: {torch.cuda.current_device()}')  # 0\n",
    "print(f'Is cuda available: {torch.cuda.is_available()}')  # TRUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68f01549-7e94-491f-823d-9c9fa23af798",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers version: 4.37.2\n",
      "Datasets version: 2.14.5\n"
     ]
    }
   ],
   "source": [
    "print(f'Transformers version: {transformers.__version__}')\n",
    "print(f'Datasets version: {datasets.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd5e8609-b918-4727-8551-16fa74ac017f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prevent a warning related to the tokenization process in the transformers library. \n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"False\"\n",
    "# Makes CUDA operations synchronous\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d1b7d84-7d7e-4cb0-bcea-64921f983495",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Apr 28 00:41:57 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090        On  | 00000000:41:00.0 Off |                  N/A |\n",
      "| 30%   30C    P8              35W / 350W |   7984MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 3090        On  | 00000000:61:00.0 Off |                  N/A |\n",
      "| 30%   25C    P8              22W / 350W |      6MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce RTX 3090        On  | 00000000:C1:00.0 Off |                  N/A |\n",
      "| 30%   24C    P8              21W / 350W |      6MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce RTX 3090        On  | 00000000:E1:00.0 Off |                  N/A |\n",
      "| 30%   24C    P8              19W / 350W |      6MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A   2259820      C   python                                     2622MiB |\n",
      "|    0   N/A  N/A   2332511      C   python                                     2622MiB |\n",
      "|    0   N/A  N/A   2967048      C   python                                      904MiB |\n",
      "|    0   N/A  N/A   2982261      C   python                                      904MiB |\n",
      "|    0   N/A  N/A   3288645      C   python                                      904MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Find the GPU with the least memory usage.\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da3c8113-128b-476f-99b1-2232d8d330dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 32% |\n",
      "|  1 |  0% |  0% |\n",
      "|  2 |  0% |  0% |\n",
      "|  3 |  0% |  0% |\n",
      "GPU Usage after emptying the cache\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 32% |\n",
      "|  1 |  5% |  1% |\n",
      "|  2 |  0% |  0% |\n",
      "|  3 |  0% |  0% |\n"
     ]
    }
   ],
   "source": [
    "def free_gpu_cache():\n",
    "    print(\"Initial GPU Usage\")\n",
    "    gpu_usage()                             \n",
    "\n",
    "    # free unreferenced tensors from the GPU memory.\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    cuda.select_device(0)\n",
    "    cuda.close()\n",
    "    cuda.select_device(0)\n",
    "\n",
    "    print(\"GPU Usage after emptying the cache\")\n",
    "    gpu_usage()\n",
    "\n",
    "free_gpu_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1a1d08c4-2c1a-44e7-a048-d9a9356fda52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_clean</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simple sftptofile integrations with charset co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the official docs are now on github as mention...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>migrate java transport client to the new high ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>make typereference inline anonymous classes co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>title updated please go ahead</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>we dont need the 0rename stuff because distcp ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>the test hasnt been flaky for some time remove...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>fair enough however that means we are leaving ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>flakey test</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>stan maybe you want to add a unit test many th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>555 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            text_clean  label\n",
       "0    simple sftptofile integrations with charset co...      0\n",
       "1    the official docs are now on github as mention...      0\n",
       "2    migrate java transport client to the new high ...      0\n",
       "3    make typereference inline anonymous classes co...      0\n",
       "4                        title updated please go ahead      0\n",
       "..                                                 ...    ...\n",
       "550  we dont need the 0rename stuff because distcp ...      1\n",
       "551  the test hasnt been flaky for some time remove...      1\n",
       "552  fair enough however that means we are leaving ...      1\n",
       "553                                        flakey test      1\n",
       "554  stan maybe you want to add a unit test many th...      1\n",
       "\n",
       "[555 rows x 2 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"clean_test_debt_or_not_test_external.csv\" , index_col = 0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a0d19ac-0b58-4eb8-bdf1-714fc7a5902d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_clean</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xml related tests are now ignored for composit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sound like a plan and you can assign me to it ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i have been able to successfully speed up the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>testscannersfuzzing currently tests compressed...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1 lgtm i would also convert the test to junitv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>yes i added a profile to run only flaky tests ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>one problem with those is that they are not a ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>thanks for detailed description ill have a loo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>the flakeyfinder fingered the above commit as ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>keystore is java default and preferred interfa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           text_clean  label\n",
       "0   xml related tests are now ignored for composit...      0\n",
       "1   sound like a plan and you can assign me to it ...      1\n",
       "2   i have been able to successfully speed up the ...      0\n",
       "3   testscannersfuzzing currently tests compressed...      0\n",
       "4   1 lgtm i would also convert the test to junitv...      0\n",
       "..                                                ...    ...\n",
       "57  yes i added a profile to run only flaky tests ...      0\n",
       "58  one problem with those is that they are not a ...      0\n",
       "59  thanks for detailed description ill have a loo...      1\n",
       "60  the flakeyfinder fingered the above commit as ...      0\n",
       "61  keystore is java default and preferred interfa...      1\n",
       "\n",
       "[62 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test_set = pd.read_csv(\"testset_test_or_not_test_clean.csv\" , index_col = 0)\n",
    "data_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13a6a7cd-4d14-4bab-83da-6f7d37604a6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Smaller and faster than bert.\n",
    "base_model_id = \"distilbert-base-uncased\"\n",
    "\n",
    "epochs = 5 #Number of full cyles through the training set.\n",
    "num_labels = 2 \n",
    "learning_rate = 5e-5 # Rate the model updates based on the data its trained on.\n",
    "train_batch_size = 16 # Number of training examples in one iteration.\n",
    "eval_batch_size = 32 # Number evalutaion examples in on iteratoion.\n",
    "save_strategy = \"no\" # Should the model be saved automatically during training.\n",
    "save_steps = 500 # How often to save the model during training. No effect since no over.\n",
    "logging_steps = 20\n",
    "model_dir = \"./model\" #Where to save model\n",
    "\n",
    "# Use early stopping to prevent overfitting\n",
    "#load_best_model_at_end=True\n",
    "#metric_for_best_model=\"eval_loss\"\n",
    "#greater_is_better=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "644b3194-eb30-4222-814b-cc3d063cbc6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split dataframe into three parts: training, validation and testing.\n",
    "def train_validate_test_split(df, train_percent=.8, validate_percent=.1, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    # Shuffle index of dataframe\n",
    "    perm = np.random.permutation(df.index)\n",
    "    \n",
    "    df_length = len(df.index)\n",
    "    \n",
    "    # Number of row in training set\n",
    "    train_end = int(train_percent * df_length)\n",
    "    # Number of rows in validate set\n",
    "    validate_end = int(validate_percent * df_length) + train_end\n",
    "    \n",
    "    # From start to train end\n",
    "    train = df.iloc[perm[:train_end]]\n",
    "    # From train_end to validate_end\n",
    "    validate = df.iloc[perm[train_end:validate_end]]\n",
    "    # From validate to the last row in dataframe.\n",
    "    test = df.iloc[perm[validate_end:]]\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4092bcdd-287a-4821-9683-ca3f1907f564",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drops rows with missing values\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9d44b78-2434-459c-b4b8-ca5dce978910",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>thrift1735 integrates python tutorials into re...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>new implementation of zlib compressed transpor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>posted a new patch which is not as radical the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1 would be good to have a test also</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>we have authorization tests that are specific ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>553</td>\n",
       "      <td>salesforce adds fields to even after an api ha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>554</td>\n",
       "      <td>fixed in there were already and but all of the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>555</td>\n",
       "      <td>intermittent time outs</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>556</td>\n",
       "      <td>thanks for the pr</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>557</td>\n",
       "      <td>done next time ill bring a lawyer with me sinc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>558 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                         text_clean  label\n",
       "0        0  thrift1735 integrates python tutorials into re...      0\n",
       "1        1  new implementation of zlib compressed transpor...      0\n",
       "2        2  posted a new patch which is not as radical the...      0\n",
       "3        3                1 would be good to have a test also      0\n",
       "4        4  we have authorization tests that are specific ...      0\n",
       "..     ...                                                ...    ...\n",
       "553    553  salesforce adds fields to even after an api ha...      1\n",
       "554    554  fixed in there were already and but all of the...      1\n",
       "555    555                             intermittent time outs      1\n",
       "556    556                                  thanks for the pr      1\n",
       "557    557  done next time ill bring a lawyer with me sinc...      1\n",
       "\n",
       "[558 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resets the index after dropping rows\n",
    "data.reset_index(inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30b0fa64-3922-46ca-a721-3dfbcb8b3ea3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Drops the index col, better for managint the data.\n",
    "data.drop(columns= [\"index\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2398a175-37bb-41a9-ab9c-c86b0b890906",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_clean</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thrift1735 integrates python tutorials into re...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>new implementation of zlib compressed transpor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>posted a new patch which is not as radical the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1 would be good to have a test also</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>we have authorization tests that are specific ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>salesforce adds fields to even after an api ha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>fixed in there were already and but all of the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>intermittent time outs</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>thanks for the pr</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>done next time ill bring a lawyer with me sinc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>558 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            text_clean  label\n",
       "0    thrift1735 integrates python tutorials into re...      0\n",
       "1    new implementation of zlib compressed transpor...      0\n",
       "2    posted a new patch which is not as radical the...      0\n",
       "3                  1 would be good to have a test also      0\n",
       "4    we have authorization tests that are specific ...      0\n",
       "..                                                 ...    ...\n",
       "553  salesforce adds fields to even after an api ha...      1\n",
       "554  fixed in there were already and but all of the...      1\n",
       "555                             intermittent time outs      1\n",
       "556                                  thanks for the pr      1\n",
       "557  done next time ill bring a lawyer with me sinc...      1\n",
       "\n",
       "[558 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02787dd7-7866-4243-9bd5-40c661ad1083",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 80% trainig, 10% validate, 10% test. Seed 42.\n",
    "# Test 80-10-10 and 70-15-15\n",
    "train , validate , test = train_validate_test_split(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2de236c-d091-451b-b157-af18a4b9dd4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.set_index(\"label\" , inplace = True)\n",
    "validate.set_index(\"label\" , inplace = True)\n",
    "test.set_index(\"label\" , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b346d9c-1417-466d-9e94-7bd373ba3056",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 code looks good is there a way to enhance an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>will be fixed in a patch for other issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jake i unfortunately have no clue how to gener...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 ravis proposal i would also add that fullyde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>roger to avoid some confusion the attached pat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the package scanning is deprecated and you sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>running more frequently seems to show that it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>we have fine grained details on each endpoint ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>raw and child endpoint issue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>migrate java transport client to the new high ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oh yes youre right using a maven plugin is not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this got rolled into chromium trunk at r36893 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>we could use thoughts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>need access to metadata about charset to use f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>looks like there are other flaky subtests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>any chance you could share the specifics on ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>when using wsimport the structure of the gener...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thank you for the hint with the rollback i am ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>we do not have any endtoend tests where we att...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i did test this manually indeed the patch is i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i believe cxf version was related to camelcxf ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>use the user forum or user mailing list to ask...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>if a custom configuration for the threadpool i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hadrian see also the chat log for yesterday ja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i was dealing with multiple patches and totall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the functional test coverage for impala on kud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clause im deploying a new version of cxf 22 sn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>we are seeing issues with gets and patch as we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>see nabble by invoking the filter for director...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nicola i wonder if you get these errors also</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in tez we provide a tez shuffle handler that i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>patch does not apply patches must be in svn di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>itd be nice to be able to pass in context para...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>never looked into restresources let me check w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trunk 798902 todo hl7 segment that fails valid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the fix looks good to me thanks for the contri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>flakey test improvements</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thanks freeman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it seem to be a small issue in tab completion ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>beaninfointrospect does not work correctly wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thanks since java9 isnt a lts java version and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i missed it checking now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>if there is no objection i plan to resolve thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>none of the above i thought you might have an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>camelgit add allowempty commits option</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>now stuck on hbase19239 many of the problems a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>we have some uri options to set some regexp fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the fix doesnt seem to be working as part if t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>please help fix and test this thrift2229 first...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>emptynull response from netty4http template pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>speed up a couple of heavyhitting exprtests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>there is hardly any test coverage for the node...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the test failed in flakies a few times last ni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>impacts the following tests at least currently...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this does not work if you have 2 out of 3 repl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this was not really intended but i am adding s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>did not run tests change in documentation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text_clean\n",
       "label                                                   \n",
       "0      1 code looks good is there a way to enhance an...\n",
       "1              will be fixed in a patch for other issues\n",
       "0      jake i unfortunately have no clue how to gener...\n",
       "0      1 ravis proposal i would also add that fullyde...\n",
       "0      roger to avoid some confusion the attached pat...\n",
       "1      the package scanning is deprecated and you sho...\n",
       "0      running more frequently seems to show that it ...\n",
       "1      we have fine grained details on each endpoint ...\n",
       "1                           raw and child endpoint issue\n",
       "1      migrate java transport client to the new high ...\n",
       "1      oh yes youre right using a maven plugin is not...\n",
       "0      this got rolled into chromium trunk at r36893 ...\n",
       "1                                  we could use thoughts\n",
       "1      need access to metadata about charset to use f...\n",
       "0              looks like there are other flaky subtests\n",
       "0      any chance you could share the specifics on ho...\n",
       "1      when using wsimport the structure of the gener...\n",
       "1      thank you for the hint with the rollback i am ...\n",
       "0      we do not have any endtoend tests where we att...\n",
       "0      i did test this manually indeed the patch is i...\n",
       "1      i believe cxf version was related to camelcxf ...\n",
       "1      use the user forum or user mailing list to ask...\n",
       "1      if a custom configuration for the threadpool i...\n",
       "1      hadrian see also the chat log for yesterday ja...\n",
       "0      i was dealing with multiple patches and totall...\n",
       "0      the functional test coverage for impala on kud...\n",
       "1      clause im deploying a new version of cxf 22 sn...\n",
       "1      we are seeing issues with gets and patch as we...\n",
       "0      see nabble by invoking the filter for director...\n",
       "1           nicola i wonder if you get these errors also\n",
       "0      in tez we provide a tez shuffle handler that i...\n",
       "0      patch does not apply patches must be in svn di...\n",
       "1      itd be nice to be able to pass in context para...\n",
       "1      never looked into restresources let me check w...\n",
       "0      trunk 798902 todo hl7 segment that fails valid...\n",
       "0      the fix looks good to me thanks for the contri...\n",
       "0                               flakey test improvements\n",
       "1                                         thanks freeman\n",
       "1      it seem to be a small issue in tab completion ...\n",
       "1      beaninfointrospect does not work correctly wit...\n",
       "1      thanks since java9 isnt a lts java version and...\n",
       "1                               i missed it checking now\n",
       "0      if there is no objection i plan to resolve thi...\n",
       "0      none of the above i thought you might have an ...\n",
       "1                 camelgit add allowempty commits option\n",
       "0      now stuck on hbase19239 many of the problems a...\n",
       "1      we have some uri options to set some regexp fo...\n",
       "1      the fix doesnt seem to be working as part if t...\n",
       "0      please help fix and test this thrift2229 first...\n",
       "1      emptynull response from netty4http template pr...\n",
       "0            speed up a couple of heavyhitting exprtests\n",
       "0      there is hardly any test coverage for the node...\n",
       "0      the test failed in flakies a few times last ni...\n",
       "0      impacts the following tests at least currently...\n",
       "0      this does not work if you have 2 out of 3 repl...\n",
       "1      this was not really intended but i am adding s...\n",
       "0              did not run tests change in documentation"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2303a1e0-4e3c-4a66-936e-84ee7b73e8a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['text_clean', 'label'],\n",
       "        num_rows: 57\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['text_clean', 'label'],\n",
       "        num_rows: 446\n",
       "    })\n",
       "    validate: Dataset({\n",
       "        features: ['text_clean', 'label'],\n",
       "        num_rows: 55\n",
       "    })\n",
       "    separate_test_set: Dataset({\n",
       "        features: ['text_clean', 'label', '__index_level_0__'],\n",
       "        num_rows: 62\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert from Pandas DataFrame to Hugging Face datasets\n",
    "tds = Dataset.from_pandas(train)\n",
    "vds = Dataset.from_pandas(validate)\n",
    "testds = Dataset.from_pandas(test)\n",
    "\n",
    "separate_test_set = Dataset.from_pandas(data_test_set)\n",
    "ds = DatasetDict()\n",
    "\n",
    "ds[\"test\"] = testds\n",
    "ds[\"train\"] = tds\n",
    "ds[\"validate\"] = vds\n",
    "ds[\"separate_test_set\"] = separate_test_set\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "975863f4-f4b2-43cd-941b-83e7486da7d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = ds[\"train\"]\n",
    "valid_dataset = ds[\"validate\"]\n",
    "test_ds = ds[\"test\"]\n",
    "separate_test_set_dataset = ds[\"separate_test_set\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5bceaba9-3261-4a04-88be-831d51fac6c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text_clean': 'this jira applies to trunk as well would you please provide a patch for trunk on the patch for the key names id remove authentication as these properties can be used for different things than authentication testcase is missing',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "054ea27f-3b88-4cb1-b02f-1d12a82ec193",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6de1f9e-9ea1-42d6-b2f6-8448d962abe0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(base_model_id, num_labels=num_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2102ca1b-6573-4b17-bd8b-ab8ebfdf189c",
   "metadata": {},
   "source": [
    "# Tokanization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7b61137-9aff-4b4c-b925-3c612e5ca9e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_ckpt = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d00c290e-d1fb-4d4b-b8a4-7436e69945b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17f2c8e063dd4795a19c850c2d63ae14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/446 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0485d20d35f04f859fb2c7bb9e9894b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/55 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a496e6c0187d4443b6bf89ff93a15d00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/57 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9196ea0a027648de8be6268cab238090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/62 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Tokenize the dataset to the correct input for the transformer model.\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text_clean\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=True, batch_size=len(train_dataset))\n",
    "valid_dataset = valid_dataset.map(tokenize, batched=True, batch_size=len(valid_dataset))\n",
    "test_dataset = test_ds.map(tokenize, batched=True, batch_size=len(test_ds))\n",
    "separate_test_set_dataset = separate_test_set_dataset.map(tokenize, batched=True, batch_size=len(separate_test_set_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62066e28-3e64-4394-8254-5d33205ce273",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=model_dir,\n",
    "    num_train_epochs=epochs,\n",
    "    per_device_train_batch_size=train_batch_size,\n",
    "    per_device_eval_batch_size=eval_batch_size,\n",
    "    save_strategy=save_strategy,\n",
    "    save_steps=save_steps,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=learning_rate,\n",
    "    logging_steps=logging_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f861feb1-3b00-4581-8577-97b41d4a8af5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8da21617-2244-4441-835a-8fc1ce2b7772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='140' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [140/140 00:28, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.581600</td>\n",
       "      <td>0.205585</td>\n",
       "      <td>0.927273</td>\n",
       "      <td>[0.92857143 0.92592593]</td>\n",
       "      <td>[0.96296296 0.89285714]</td>\n",
       "      <td>[0.89655172 0.96153846]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.202700</td>\n",
       "      <td>0.098219</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>[0.98305085 0.98039216]</td>\n",
       "      <td>[0.96666667 1.        ]</td>\n",
       "      <td>[1.         0.96153846]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.113300</td>\n",
       "      <td>0.066145</td>\n",
       "      <td>0.963636</td>\n",
       "      <td>[0.96551724 0.96153846]</td>\n",
       "      <td>[0.96551724 0.96153846]</td>\n",
       "      <td>[0.96551724 0.96153846]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.087100</td>\n",
       "      <td>0.063598</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>[0.98305085 0.98039216]</td>\n",
       "      <td>[0.96666667 1.        ]</td>\n",
       "      <td>[1.         0.96153846]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.053500</td>\n",
       "      <td>0.053812</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>[0.98305085 0.98039216]</td>\n",
       "      <td>[0.96666667 1.        ]</td>\n",
       "      <td>[1.         0.96153846]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"[0.92857143 0.92592593]\" of type <class 'numpy.ndarray'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.96296296 0.89285714]\" of type <class 'numpy.ndarray'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.89655172 0.96153846]\" of type <class 'numpy.ndarray'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.98305085 0.98039216]\" of type <class 'numpy.ndarray'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.96666667 1.        ]\" of type <class 'numpy.ndarray'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[1.         0.96153846]\" of type <class 'numpy.ndarray'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.96551724 0.96153846]\" of type <class 'numpy.ndarray'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.96551724 0.96153846]\" of type <class 'numpy.ndarray'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.96551724 0.96153846]\" of type <class 'numpy.ndarray'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.98305085 0.98039216]\" of type <class 'numpy.ndarray'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.96666667 1.        ]\" of type <class 'numpy.ndarray'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[1.         0.96153846]\" of type <class 'numpy.ndarray'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.98305085 0.98039216]\" of type <class 'numpy.ndarray'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.96666667 1.        ]\" of type <class 'numpy.ndarray'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[1.         0.96153846]\" of type <class 'numpy.ndarray'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=140, training_loss=0.19131566030638558, metrics={'train_runtime': 29.1163, 'train_samples_per_second': 76.589, 'train_steps_per_second': 4.808, 'total_flos': 295402299002880.0, 'train_loss': 0.19131566030638558, 'epoch': 5.0})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ece97dd-c2f8-4e97-80be-90318c176c46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"[0.98305085 0.98039216]\" of type <class 'numpy.ndarray'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.96666667 1.        ]\" of type <class 'numpy.ndarray'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[1.         0.96153846]\" of type <class 'numpy.ndarray'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    }
   ],
   "source": [
    "eval_result = trainer.evaluate(eval_dataset=valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9d3961b0-680f-4753-a2f8-708c3f408cc0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 5.0\n",
      "\n",
      "eval_accuracy = 0.9818181818181818\n",
      "\n",
      "eval_f1 = [0.98305085 0.98039216]\n",
      "\n",
      "eval_loss = 0.05381222069263458\n",
      "\n",
      "eval_precision = [0.96666667 1.        ]\n",
      "\n",
      "eval_recall = [1.         0.96153846]\n",
      "\n",
      "eval_runtime = 0.2353\n",
      "\n",
      "eval_samples_per_second = 233.759\n",
      "\n",
      "eval_steps_per_second = 8.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, value in sorted(eval_result.items()):\n",
    "    print(f\"{key} = {value}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c384cc8-1b5e-4161-8f0b-230a3d453637",
   "metadata": {},
   "source": [
    "## Training loss decreases, valdiation loss increases = Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b77cc45b-1d9e-47d7-b73a-c56a4ff77ec7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"[1. 1.]\" of type <class 'numpy.ndarray'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[1. 1.]\" of type <class 'numpy.ndarray'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[1. 1.]\" of type <class 'numpy.ndarray'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    }
   ],
   "source": [
    "# Evaluate test data set\n",
    "test_results = trainer.evaluate(eval_dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d57397f6-5a08-4562-824e-642b03d0ce3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 5.0\n",
      "\n",
      "eval_accuracy = 1.0\n",
      "\n",
      "eval_f1 = [1. 1.]\n",
      "\n",
      "eval_loss = 0.010014262050390244\n",
      "\n",
      "eval_precision = [1. 1.]\n",
      "\n",
      "eval_recall = [1. 1.]\n",
      "\n",
      "eval_runtime = 0.2426\n",
      "\n",
      "eval_samples_per_second = 234.91\n",
      "\n",
      "eval_steps_per_second = 8.242\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, value in sorted(test_results.items()):\n",
    "    print(f\"{key} = {value}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73018a46-ce85-4b2c-971f-580c684d2ae3",
   "metadata": {},
   "source": [
    "# Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "90cd7bb6-6c93-478f-bbf0-ba28e6e9f9e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"[0.97222222 0.96153846]\" of type <class 'numpy.ndarray'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.94594595 1.        ]\" of type <class 'numpy.ndarray'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[1.         0.92592593]\" of type <class 'numpy.ndarray'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    }
   ],
   "source": [
    "separate_test_set_results = trainer.evaluate(eval_dataset=separate_test_set_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1b2c9011-0a0b-41a4-9890-f8b572201155",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 5.0\n",
      "\n",
      "eval_accuracy = 0.967741935483871\n",
      "\n",
      "eval_f1 = [0.97222222 0.96153846]\n",
      "\n",
      "eval_loss = 0.0909014567732811\n",
      "\n",
      "eval_precision = [0.94594595 1.        ]\n",
      "\n",
      "eval_recall = [1.         0.92592593]\n",
      "\n",
      "eval_runtime = 0.268\n",
      "\n",
      "eval_samples_per_second = 231.33\n",
      "\n",
      "eval_steps_per_second = 7.462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, value in sorted(separate_test_set_results.items()):\n",
    "    print(f\"{key} = {value}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "38713ff0-d6c7-4016-a4a8-29a42d65c926",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.save_model(model_dir + \"_local\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "35467216-6f3d-4e00-a836-2d72510cbfb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "    \n",
    "classifier = pipeline(\"text-classification\", model=\"./model_local\", truncation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c63e264c-607c-49ba-b283-d623d47fdb04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b2246fcd-713c-40bd-9230-63797d2181a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.9676269888877869}]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"this contain bugs regarding testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d2e0a903-6900-443a-8c80-c45b798026ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.9849045276641846}]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"this contain bugs regarding automtion not testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "38318df6-498f-4b6e-983d-4962b18f6179",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_1', 'score': 0.9777336716651917}]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"this bug has super high impact on the project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cf3a5463-a4d2-4aed-b15d-ccd51a95c38b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_clean</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>make sure integration tests are running with i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cover anvil service response in unit testshttp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>service apprepositorycontroller should be cach...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>many caches persist between test casesan examp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>improve friendliness of behat text pattern mat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          text_clean  label\n",
       "0  make sure integration tests are running with i...      1\n",
       "1  cover anvil service response in unit testshttp...      1\n",
       "2  service apprepositorycontroller should be cach...      1\n",
       "3  many caches persist between test casesan examp...      1\n",
       "4  improve friendliness of behat text pattern mat...      1"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('clean_test_or_not_test_debt.csv',index_col = 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3fb5177d-0c71-4e43-89c4-49fa5d38443a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for index, row in df.iterrows():\n",
    "    # Encode the text, truncate to the max length, and convert to the format expected by the classifier\n",
    "    inputs = tokenizer.encode(row['text_clean'], return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    \n",
    "    # Since the pipeline expects a string, we decode the tokens to get a truncated string representation\n",
    "    truncated_text = tokenizer.decode(inputs[0])\n",
    "    \n",
    "    prediction = classifier(truncated_text)\n",
    "    predicted_label = prediction[0]['label']\n",
    "    prediction_confidence = prediction[0]['score']\n",
    "    \n",
    "    # Append the result as a tuple\n",
    "    results.append((row['text_clean'], row['label'], predicted_label, prediction_confidence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "003c562f-6418-40e2-abab-ca36f6d0f577",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>actual_type</th>\n",
       "      <th>predicted_type</th>\n",
       "      <th>prediction_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>make sure integration tests are running with i...</td>\n",
       "      <td>1</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>0.987613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cover anvil service response in unit testshttp...</td>\n",
       "      <td>1</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>0.961769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>service apprepositorycontroller should be cach...</td>\n",
       "      <td>1</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>0.994962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>many caches persist between test casesan examp...</td>\n",
       "      <td>1</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>0.959566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>improve friendliness of behat text pattern mat...</td>\n",
       "      <td>1</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>0.985052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>investigate timeout circleci failed builds sum...</td>\n",
       "      <td>0</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>0.982028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>investigate moving off of direct googleprotobu...</td>\n",
       "      <td>0</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>0.995170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>replace ansiterm with consolewe are currently ...</td>\n",
       "      <td>0</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>0.996914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>update key naming strategies to be in line wit...</td>\n",
       "      <td>0</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>0.997013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>stop using commonh unnecessary dependeciesusin...</td>\n",
       "      <td>0</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>0.996323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>485 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            clean_text  actual_type  \\\n",
       "0    make sure integration tests are running with i...            1   \n",
       "1    cover anvil service response in unit testshttp...            1   \n",
       "2    service apprepositorycontroller should be cach...            1   \n",
       "3    many caches persist between test casesan examp...            1   \n",
       "4    improve friendliness of behat text pattern mat...            1   \n",
       "..                                                 ...          ...   \n",
       "480  investigate timeout circleci failed builds sum...            0   \n",
       "481  investigate moving off of direct googleprotobu...            0   \n",
       "482  replace ansiterm with consolewe are currently ...            0   \n",
       "483  update key naming strategies to be in line wit...            0   \n",
       "484  stop using commonh unnecessary dependeciesusin...            0   \n",
       "\n",
       "    predicted_type  prediction_accuracy  \n",
       "0          LABEL_0             0.987613  \n",
       "1          LABEL_0             0.961769  \n",
       "2          LABEL_1             0.994962  \n",
       "3          LABEL_0             0.959566  \n",
       "4          LABEL_0             0.985052  \n",
       "..             ...                  ...  \n",
       "480        LABEL_0             0.982028  \n",
       "481        LABEL_1             0.995170  \n",
       "482        LABEL_1             0.996914  \n",
       "483        LABEL_1             0.997013  \n",
       "484        LABEL_1             0.996323  \n",
       "\n",
       "[485 rows x 4 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results, columns=['clean_text', 'actual_type', 'predicted_type', 'prediction_accuracy'])\n",
    "# Display the first few rows of the results DataFrame\n",
    "results_df.head(-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f5b7792b-547e-4b0a-a3ab-a389b089d013",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>actual_type</th>\n",
       "      <th>predicted_type</th>\n",
       "      <th>prediction_accuracy</th>\n",
       "      <th>predicted_type_numeric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>make sure integration tests are running with i...</td>\n",
       "      <td>1</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>0.987613</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cover anvil service response in unit testshttp...</td>\n",
       "      <td>1</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>0.961769</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>service apprepositorycontroller should be cach...</td>\n",
       "      <td>1</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>0.994962</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>many caches persist between test casesan examp...</td>\n",
       "      <td>1</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>0.959566</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>improve friendliness of behat text pattern mat...</td>\n",
       "      <td>1</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>0.985052</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>investigate timeout circleci failed builds sum...</td>\n",
       "      <td>0</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>0.982028</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>investigate moving off of direct googleprotobu...</td>\n",
       "      <td>0</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>0.995170</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>replace ansiterm with consolewe are currently ...</td>\n",
       "      <td>0</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>0.996914</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>update key naming strategies to be in line wit...</td>\n",
       "      <td>0</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>0.997013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>stop using commonh unnecessary dependeciesusin...</td>\n",
       "      <td>0</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>0.996323</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>485 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            clean_text  actual_type  \\\n",
       "0    make sure integration tests are running with i...            1   \n",
       "1    cover anvil service response in unit testshttp...            1   \n",
       "2    service apprepositorycontroller should be cach...            1   \n",
       "3    many caches persist between test casesan examp...            1   \n",
       "4    improve friendliness of behat text pattern mat...            1   \n",
       "..                                                 ...          ...   \n",
       "480  investigate timeout circleci failed builds sum...            0   \n",
       "481  investigate moving off of direct googleprotobu...            0   \n",
       "482  replace ansiterm with consolewe are currently ...            0   \n",
       "483  update key naming strategies to be in line wit...            0   \n",
       "484  stop using commonh unnecessary dependeciesusin...            0   \n",
       "\n",
       "    predicted_type  prediction_accuracy  predicted_type_numeric  \n",
       "0          LABEL_0             0.987613                       0  \n",
       "1          LABEL_0             0.961769                       0  \n",
       "2          LABEL_1             0.994962                       1  \n",
       "3          LABEL_0             0.959566                       0  \n",
       "4          LABEL_0             0.985052                       0  \n",
       "..             ...                  ...                     ...  \n",
       "480        LABEL_0             0.982028                       0  \n",
       "481        LABEL_1             0.995170                       1  \n",
       "482        LABEL_1             0.996914                       1  \n",
       "483        LABEL_1             0.997013                       1  \n",
       "484        LABEL_1             0.996323                       1  \n",
       "\n",
       "[485 rows x 5 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_predicted_label_to_numeric(label_str):\n",
    "    # Extract the numeric part from the label string and convert it to an integer\n",
    "    return int(label_str.split('_')[-1])\n",
    "\n",
    "# Apply the conversion function to the 'predicted_type' column\n",
    "results_df['predicted_type_numeric'] = results_df['predicted_type'].apply(convert_predicted_label_to_numeric)\n",
    "results_df.head(-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "884a04e1-cf1d-4639-a719-db84939da7ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2163265306122449\n",
      "F1 Score: 0.16521739130434784\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Assuming 'actual_type' is already in the correct numeric format\n",
    "accuracy = accuracy_score(results_df['actual_type'], results_df['predicted_type_numeric'])\n",
    "f1 = f1_score(results_df['actual_type'], results_df['predicted_type_numeric'], average='binary')  # Adjust as needed\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2d692679-81f0-42d5-9b9b-5b43fc833565",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_df.to_csv('TestNotTestRes_bert.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa24caac-2ca2-45fa-a547-1122d66927d6",
   "metadata": {},
   "source": [
    "### Delete the dataset with large memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0ad0df6f-2507-4be1-a026-43145120c661",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6013e6b7-e0f6-4755-a8ab-0eaabdd95c4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ed059002-d156-431c-8556-c7152abe62ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Free cache\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "86114411-d883-48d6-a960-f90726d8ae2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jan  3 13:44:38 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:01:00.0 Off |                  N/A |\n",
      "| 22%   34C    P8              18W / 250W |   3949MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:24:00.0 Off |                  N/A |\n",
      "| 42%   69C    P2             248W / 250W |   7143MiB / 11264MiB |    100%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:41:00.0 Off |                  N/A |\n",
      "| 43%   71C    P2             245W / 250W |   7143MiB / 11264MiB |     99%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:61:00.0 Off |                  N/A |\n",
      "| 37%   63C    P2             249W / 250W |   7143MiB / 11264MiB |    100%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:81:00.0 Off |                  N/A |\n",
      "| 41%   67C    P2             242W / 250W |   7143MiB / 11264MiB |    100%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:A1:00.0 Off |                  N/A |\n",
      "| 22%   30C    P8               5W / 250W |   4085MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:C1:00.0 Off |                  N/A |\n",
      "| 22%   31C    P8              16W / 250W |   1211MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:E1:00.0 Off |                  N/A |\n",
      "| 22%   25C    P8              12W / 250W |      3MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A   3186306      C   ...home/matan/venvs/ptmatan/bin/python     3944MiB |\n",
      "|    1   N/A  N/A   1388412      C   ...ml/home/limeng/torch_env/bin/python     7136MiB |\n",
      "|    2   N/A  N/A   1388413      C   ...ml/home/limeng/torch_env/bin/python     7136MiB |\n",
      "|    3   N/A  N/A   1388414      C   ...ml/home/limeng/torch_env/bin/python     7136MiB |\n",
      "|    4   N/A  N/A   1388415      C   ...ml/home/limeng/torch_env/bin/python     7136MiB |\n",
      "|    5   N/A  N/A   3186306      C   ...home/matan/venvs/ptmatan/bin/python     4080MiB |\n",
      "|    6   N/A  N/A    773617      C   ...ome/nehad/.conda/envs/dl/bin/python     1208MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849b32d3-e0b5-4bf2-97cb-cfc68e81c216",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
