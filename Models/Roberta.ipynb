{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86876e4a-ae69-4ac6-8ce9-a7e3ae7d437e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76810fd8-a9ba-4daf-b972-762aaef5dd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9efc75ea-5fc9-4a40-9c08-c00203b7199f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !watch -n 0.5 nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a0eb504-1e95-48af-aeb2-e8734870b0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0\n",
      "11.3\n",
      "8201\n",
      "0\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)  # 1.9.1+cu111\n",
    "print(torch.version.cuda)  # 11.1\n",
    "print(torch.backends.cudnn.version())  # 8005\n",
    "print(torch.cuda.current_device())  # 0\n",
    "print(torch.cuda.is_available())  # TRUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "179dcc0a-000e-4009-b7d6-57a8bae7d4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"True\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54e46c7b-8d4b-42b8-ae9c-6c7d43bb1d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Aug  2 23:47:09 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0 Off |                  N/A |\n",
      "| 22%   25C    P8    15W / 250W |      1MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  On   | 00000000:23:00.0 Off |                  N/A |\n",
      "| 22%   25C    P8     7W / 250W |   2093MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce ...  On   | 00000000:41:00.0 Off |                  N/A |\n",
      "| 22%   31C    P2    57W / 250W |   1688MiB / 11019MiB |      1%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce ...  On   | 00000000:61:00.0 Off |                  N/A |\n",
      "| 28%   49C    P2   225W / 250W |   6748MiB / 11019MiB |     90%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA GeForce ...  On   | 00000000:81:00.0 Off |                  N/A |\n",
      "| 22%   27C    P8    24W / 250W |      1MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA GeForce ...  On   | 00000000:A1:00.0 Off |                  N/A |\n",
      "| 27%   48C    P2   192W / 250W |   2802MiB / 11019MiB |     40%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA GeForce ...  On   | 00000000:C1:00.0 Off |                  N/A |\n",
      "| 22%   33C    P2    71W / 250W |   7436MiB / 11019MiB |     36%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA GeForce ...  On   | 00000000:E1:00.0 Off |                  N/A |\n",
      "| 22%   25C    P8    31W / 250W |      1MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    1   N/A  N/A    773637      C   ...core-11.2.0/bin/python3.9     1939MiB |\n",
      "|    1   N/A  N/A   1568006      C   ...core-11.2.0/bin/python3.9      151MiB |\n",
      "|    2   N/A  N/A   4185318      C   python3                          1681MiB |\n",
      "|    3   N/A  N/A   2449359      C   python                           2797MiB |\n",
      "|    3   N/A  N/A   2463154      C   python                           2797MiB |\n",
      "|    3   N/A  N/A   3258387      C   python                           1149MiB |\n",
      "|    5   N/A  N/A   1587331      C   python                           2797MiB |\n",
      "|    6   N/A  N/A   3823451      C   python                           7431MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "499ba33b-26e7-4629-a398-9d8c098f2f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  0% |\n",
      "|  1 |  0% | 19% |\n",
      "|  2 |  1% | 15% |\n",
      "|  3 | 86% | 61% |\n",
      "|  4 |  0% |  0% |\n",
      "|  5 | 46% | 25% |\n",
      "|  6 | 34% | 67% |\n",
      "|  7 |  0% |  0% |\n",
      "GPU Usage after emptying the cache\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  0% |\n",
      "|  1 |  1% | 19% |\n",
      "|  2 |  0% | 15% |\n",
      "|  3 | 80% | 61% |\n",
      "|  4 |  0% |  0% |\n",
      "|  5 | 46% | 25% |\n",
      "|  6 | 34% | 67% |\n",
      "|  7 |  0% |  0% |\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from GPUtil import showUtilization as gpu_usage\n",
    "from numba import cuda\n",
    "\n",
    "def free_gpu_cache():\n",
    "    print(\"Initial GPU Usage\")\n",
    "    gpu_usage()                             \n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    cuda.select_device(0)\n",
    "    cuda.close()\n",
    "    cuda.select_device(0)\n",
    "\n",
    "    print(\"GPU Usage after emptying the cache\")\n",
    "    gpu_usage()\n",
    "\n",
    "free_gpu_cache()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1286125-81ef-4e56-85f0-229bd7ebf8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"TD_dataset_clean.csv\" , index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c10dfb05-8aa2-46af-befb-db7f66dc57c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_clean</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>look for min file instead</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>as an extension of 78</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bountysourceplugin want to back this issue pla...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>our grunt script is out of control its current...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jshint is dropping stylerelated support it see...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127686</th>\n",
       "      <td>ci is no more ok all i could see right now is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127687</th>\n",
       "      <td>agentwebfragment ÊâìÂºÄÂÖ∂‰ªñÁΩëÂùÄÊ≤°ÈóÆÈ¢òÔºåÊâìÂºÄhttpsopenapialipa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127688</th>\n",
       "      <td>this wouldnt quite be the same as an installpa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127689</th>\n",
       "      <td>oh no a bug it happens thanks for reporting an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127690</th>\n",
       "      <td>hi all describe the bug pyforcefieldconstraint...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127691 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               text_clean  label\n",
       "0                               look for min file instead      1\n",
       "1                                   as an extension of 78      1\n",
       "2       bountysourceplugin want to back this issue pla...      1\n",
       "3       our grunt script is out of control its current...      1\n",
       "4       jshint is dropping stylerelated support it see...      1\n",
       "...                                                   ...    ...\n",
       "127686  ci is no more ok all i could see right now is ...      0\n",
       "127687  agentwebfragment ÊâìÂºÄÂÖ∂‰ªñÁΩëÂùÄÊ≤°ÈóÆÈ¢òÔºåÊâìÂºÄhttpsopenapialipa...      0\n",
       "127688  this wouldnt quite be the same as an installpa...      0\n",
       "127689  oh no a bug it happens thanks for reporting an...      0\n",
       "127690  hi all describe the bug pyforcefieldconstraint...      0\n",
       "\n",
       "[127691 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08a259d6-0d8f-439e-b45e-53d60afbed0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.21.0\n",
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import transformers\n",
    "\n",
    "print(transformers.__version__)\n",
    "print(datasets.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb4abf33-6386-47ab-b3ea-e6e84790f8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset, Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fdc4e718-8d69-4005-bd0d-5a83196c08bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9a30cdd-8023-40f7-bc45-aa12db307910",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_id = \"xlm-roberta-base\"\n",
    "\n",
    "epochs = 5\n",
    "num_labels = 2 \n",
    "learning_rate = 2e-5\n",
    "train_batch_size = 16\n",
    "eval_batch_size = 32\n",
    "save_strategy = \"no\"\n",
    "save_steps = 500\n",
    "logging_steps = 100\n",
    "\n",
    "model_dir = \"./model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf0f3ec8-7b2d-4163-9166-7ac43efac73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def train_validate_test_split(df, train_percent=.6, validate_percent=.2, seed=None):\n",
    "    np.random.seed(seed)\n",
    "    perm = np.random.permutation(df.index)\n",
    "    m = len(df.index)\n",
    "    train_end = int(train_percent * m)\n",
    "    validate_end = int(validate_percent * m) + train_end\n",
    "    train = df.iloc[perm[:train_end]]\n",
    "    validate = df.iloc[perm[train_end:validate_end]]\n",
    "    test = df.iloc[perm[validate_end:]]\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3182ddb-061d-4334-9ee9-6a2ee328e53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "522f2754-39ac-4b3f-96b9-d37936544f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7671d782-78ba-4b00-99b1-960f9c0fbf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns= [\"index\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "661accab-d00f-42b3-a6c1-856f6498ca38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_clean</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>look for min file instead</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>as an extension of 78</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bountysourceplugin want to back this issue pla...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>our grunt script is out of control its current...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jshint is dropping stylerelated support it see...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127671</th>\n",
       "      <td>ci is no more ok all i could see right now is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127672</th>\n",
       "      <td>agentwebfragment ÊâìÂºÄÂÖ∂‰ªñÁΩëÂùÄÊ≤°ÈóÆÈ¢òÔºåÊâìÂºÄhttpsopenapialipa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127673</th>\n",
       "      <td>this wouldnt quite be the same as an installpa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127674</th>\n",
       "      <td>oh no a bug it happens thanks for reporting an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127675</th>\n",
       "      <td>hi all describe the bug pyforcefieldconstraint...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127676 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               text_clean  label\n",
       "0                               look for min file instead      1\n",
       "1                                   as an extension of 78      1\n",
       "2       bountysourceplugin want to back this issue pla...      1\n",
       "3       our grunt script is out of control its current...      1\n",
       "4       jshint is dropping stylerelated support it see...      1\n",
       "...                                                   ...    ...\n",
       "127671  ci is no more ok all i could see right now is ...      0\n",
       "127672  agentwebfragment ÊâìÂºÄÂÖ∂‰ªñÁΩëÂùÄÊ≤°ÈóÆÈ¢òÔºåÊâìÂºÄhttpsopenapialipa...      0\n",
       "127673  this wouldnt quite be the same as an installpa...      0\n",
       "127674  oh no a bug it happens thanks for reporting an...      0\n",
       "127675  hi all describe the bug pyforcefieldconstraint...      0\n",
       "\n",
       "[127676 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c66a9eba-a3be-4bd2-8871-e0a969c89c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train , validate , test = train_validate_test_split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "87e4139a-da82-48ea-82d0-3c108fbc568c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train.set_index(\"label\" , inplace = True)\n",
    "validate.set_index(\"label\" , inplace = True)\n",
    "test.set_index(\"label\" , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4e5eaef-189e-4aef-b599-b6fd9e3ed985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi again üëãüèª describe the problem using unknown...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>as a developer i need a way to store the state...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>currently graphene uses a custom scalar type t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>describe the bug extension creates a new html ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>here is for fxbtcjpy press any key to continue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>idgeneration script can take care of creating ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>from google failed to create containerd task f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>describe the bug although freetypedll is prese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sql show sqlalchemygettablecomment tables like...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>if image is unsupported media type for some op...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25536 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text_clean\n",
       "label                                                   \n",
       "0      hi again üëãüèª describe the problem using unknown...\n",
       "1      as a developer i need a way to store the state...\n",
       "1      currently graphene uses a custom scalar type t...\n",
       "0      describe the bug extension creates a new html ...\n",
       "0      here is for fxbtcjpy press any key to continue...\n",
       "...                                                  ...\n",
       "0      idgeneration script can take care of creating ...\n",
       "0      from google failed to create containerd task f...\n",
       "0      describe the bug although freetypedll is prese...\n",
       "0      sql show sqlalchemygettablecomment tables like...\n",
       "1      if image is unsupported media type for some op...\n",
       "\n",
       "[25536 rows x 1 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572b19a0-5e59-414f-86a7-5a27b94febd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a3e6f629-d8fb-4537-a2cd-37d23581c84c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['text_clean', 'label'],\n",
       "        num_rows: 25536\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['text_clean', 'label'],\n",
       "        num_rows: 76605\n",
       "    })\n",
       "    validate: Dataset({\n",
       "        features: ['text_clean', 'label'],\n",
       "        num_rows: 25535\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tds = Dataset.from_pandas(train)\n",
    "vds = Dataset.from_pandas(validate)\n",
    "testds = Dataset.from_pandas(test)\n",
    "\n",
    "ds = DatasetDict()\n",
    "\n",
    "ds[\"test\"] = testds\n",
    "ds[\"train\"] = tds\n",
    "ds[\"validate\"] = vds\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d8fc417-44e4-4f8a-9148-7cd4c2a068c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ds[\"train\"]\n",
    "valid_dataset = ds[\"validate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a570f5e-3312-4005-8fa3-dc6787abe6cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text_clean': 'as a user when certain events happen i should get an in app notification new message from supportermenstruater app news allow users to get text message andor email notifications as well',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"train\"][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ddc5dc57-4dd0-4426-a7bc-1879db379711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "89217897-605d-4e42-91a7-5ecb60e78be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'roberta.pooler.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(base_model_id, num_labels=num_labels)\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id)\n",
    "# optim = torch.optim.Adam(model.parameters(), lr=5e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "39754469-d2c2-412b-b0de-daa3110a397b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b75ec313c974e018be3997af72ab7ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b14ca10c7a74decbca3b2cd51cd1f37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " def tokenize(batch):\n",
    "    return tokenizer(batch[\"text_clean\"], padding=\"max_length\", max_length=256,truncation=True)\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=True, batch_size=len(train_dataset))\n",
    "valid_dataset = valid_dataset.map(tokenize, batched=True, batch_size=len(valid_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "21396d25-3e29-4a36-acf7-d5aea28268fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=model_dir,\n",
    "    num_train_epochs=epochs,\n",
    "    per_device_train_batch_size=train_batch_size,\n",
    "    per_device_eval_batch_size=eval_batch_size,\n",
    "    save_strategy=save_strategy,\n",
    "    save_steps=save_steps,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=learning_rate,\n",
    "    logging_steps=logging_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8dbc3b2f-d33a-4795-9aa9-9fea6270662c",
   "metadata": {},
   "outputs": [],
   "source": [
    " trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "59719f9c-d921-45dc-9be9-f53c431da859",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text_clean. If text_clean are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/itf-fi-ml/home/karths/.local/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 76605\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23940\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23940' max='23940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23940/23940 4:02:55, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.352900</td>\n",
       "      <td>0.336046</td>\n",
       "      <td>0.860192</td>\n",
       "      <td>[0.87721832 0.837683  ]</td>\n",
       "      <td>[0.85896141 0.8619012 ]</td>\n",
       "      <td>[0.89626818 0.81478861]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.272500</td>\n",
       "      <td>0.325831</td>\n",
       "      <td>0.872763</td>\n",
       "      <td>[0.88835435 0.85210979]</td>\n",
       "      <td>[0.86915008 0.87780174]</td>\n",
       "      <td>[0.90842645 0.827879  ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.227400</td>\n",
       "      <td>0.369067</td>\n",
       "      <td>0.875622</td>\n",
       "      <td>[0.88978345 0.85728408]</td>\n",
       "      <td>[0.87886474 0.87130069]</td>\n",
       "      <td>[0.90097688 0.8437113 ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.189300</td>\n",
       "      <td>0.401042</td>\n",
       "      <td>0.872567</td>\n",
       "      <td>[0.8879245  0.85233255]</td>\n",
       "      <td>[0.87065181 0.87520969]</td>\n",
       "      <td>[0.90589641 0.83062091]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.161100</td>\n",
       "      <td>0.525056</td>\n",
       "      <td>0.876013</td>\n",
       "      <td>[0.8904953  0.85711707]</td>\n",
       "      <td>[0.87672819 0.87504607]</td>\n",
       "      <td>[0.90470167 0.83990801]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text_clean. If text_clean are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25535\n",
      "  Batch size = 32\n",
      "Trainer is attempting to log a value of \"[0.87721832 0.837683  ]\" of type <class 'numpy.ndarray'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.85896141 0.8619012 ]\" of type <class 'numpy.ndarray'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.89626818 0.81478861]\" of type <class 'numpy.ndarray'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text_clean. If text_clean are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25535\n",
      "  Batch size = 32\n",
      "Trainer is attempting to log a value of \"[0.88835435 0.85210979]\" of type <class 'numpy.ndarray'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.86915008 0.87780174]\" of type <class 'numpy.ndarray'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.90842645 0.827879  ]\" of type <class 'numpy.ndarray'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text_clean. If text_clean are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25535\n",
      "  Batch size = 32\n",
      "Trainer is attempting to log a value of \"[0.88978345 0.85728408]\" of type <class 'numpy.ndarray'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.87886474 0.87130069]\" of type <class 'numpy.ndarray'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.90097688 0.8437113 ]\" of type <class 'numpy.ndarray'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text_clean. If text_clean are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25535\n",
      "  Batch size = 32\n",
      "Trainer is attempting to log a value of \"[0.8879245  0.85233255]\" of type <class 'numpy.ndarray'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.87065181 0.87520969]\" of type <class 'numpy.ndarray'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.90589641 0.83062091]\" of type <class 'numpy.ndarray'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text_clean. If text_clean are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25535\n",
      "  Batch size = 32\n",
      "Trainer is attempting to log a value of \"[0.8904953  0.85711707]\" of type <class 'numpy.ndarray'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.87672819 0.87504607]\" of type <class 'numpy.ndarray'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.90470167 0.83990801]\" of type <class 'numpy.ndarray'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=23940, training_loss=0.2569883647917108, metrics={'train_runtime': 14576.8097, 'train_samples_per_second': 26.276, 'train_steps_per_second': 1.642, 'total_flos': 5.0389055989632e+16, 'train_loss': 0.2569883647917108, 'epoch': 5.0})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8941fbc3-a492-4d7b-9595-fabd30c36b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text_clean. If text_clean are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25535\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='798' max='798' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [798/798 03:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"[0.8904953  0.85711707]\" of type <class 'numpy.ndarray'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.87672819 0.87504607]\" of type <class 'numpy.ndarray'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.90470167 0.83990801]\" of type <class 'numpy.ndarray'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    }
   ],
   "source": [
    "eval_result = trainer.evaluate(eval_dataset=valid_dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7d2dddcc-4e8e-4429-88f4-ccfe2caaec65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./model_local_roberta\n",
      "Configuration saved in ./model_local_roberta/config.json\n",
      "Model weights saved in ./model_local_roberta/pytorch_model.bin\n",
      "tokenizer config file saved in ./model_local_roberta/tokenizer_config.json\n",
      "Special tokens file saved in ./model_local_roberta/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(model_dir + \"_local_roberta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "21744f4e-1fdb-4eeb-93bf-acdbac060d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in ./model_local_tokensizer_roberta/tokenizer_config.json\n",
      "Special tokens file saved in ./model_local_tokensizer_roberta/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./model_local_tokensizer_roberta/tokenizer_config.json',\n",
       " './model_local_tokensizer_roberta/special_tokens_map.json',\n",
       " './model_local_tokensizer_roberta/sentencepiece.bpe.model',\n",
       " './model_local_tokensizer_roberta/added_tokens.json',\n",
       " './model_local_tokensizer_roberta/tokenizer.json')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(model_dir + \"_local_tokensizer_roberta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c08ed1d5-64d2-4297-8b7d-10e9fb236d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 5.0\n",
      "\n",
      "eval_accuracy = 0.8760133150577638\n",
      "\n",
      "eval_f1 = [0.8904953  0.85711707]\n",
      "\n",
      "eval_loss = 0.5250561237335205\n",
      "\n",
      "eval_precision = [0.87672819 0.87504607]\n",
      "\n",
      "eval_recall = [0.90470167 0.83990801]\n",
      "\n",
      "eval_runtime = 197.3403\n",
      "\n",
      "eval_samples_per_second = 129.396\n",
      "\n",
      "eval_steps_per_second = 4.044\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, value in sorted(eval_result.items()):\n",
    "    print(f\"{key} = {value}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec71f53a-5b3a-4573-8576-4f2f909a07e3",
   "metadata": {},
   "outputs": [],
   "source": [
    " from transformers import pipeline\n",
    "    \n",
    "classifier = pipeline(\"text-classification\", model=\"./model_local_roberta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94bbafa-6752-490b-aef4-b28198a8de20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9780e1c8-59ef-4f94-8cc1-51de47297499",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d59f3784-1228-4e19-8d7b-584fa2c8218b",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "304ff834-53ae-41c3-aa97-d29aee93d888",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7afece32-fd8d-49a3-a017-5ad5bd0ff505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Tue Aug  2 11:52:53 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0 Off |                  N/A |\n",
      "| 22%   25C    P8    15W / 250W |      1MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  On   | 00000000:23:00.0 Off |                  N/A |\n",
      "| 22%   25C    P8     7W / 250W |  11008MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce ...  On   | 00000000:41:00.0 Off |                  N/A |\n",
      "| 22%   32C    P2    57W / 250W |   1688MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce ...  On   | 00000000:61:00.0 Off |                  N/A |\n",
      "| 25%   48C    P2   218W / 250W |   6748MiB / 11019MiB |     82%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA GeForce ...  On   | 00000000:81:00.0 Off |                  N/A |\n",
      "| 22%   27C    P8    23W / 250W |      1MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA GeForce ...  On   | 00000000:A1:00.0 Off |                  N/A |\n",
      "| 23%   45C    P2   190W / 250W |   2802MiB / 11019MiB |     29%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA GeForce ...  On   | 00000000:C1:00.0 Off |                  N/A |\n",
      "| 22%   33C    P2    76W / 250W |   7436MiB / 11019MiB |     38%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA GeForce ...  On   | 00000000:E1:00.0 Off |                  N/A |\n",
      "| 22%   25C    P8    31W / 250W |      1MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    1   N/A  N/A   3331446      C   ...core-11.2.0/bin/python3.9    11005MiB |\n",
      "|    2   N/A  N/A   4185318      C   python3                          1681MiB |\n",
      "|    3   N/A  N/A   2449359      C   python                           2797MiB |\n",
      "|    3   N/A  N/A   2463154      C   python                           2797MiB |\n",
      "|    3   N/A  N/A   3258387      C   python                           1149MiB |\n",
      "|    5   N/A  N/A   1587331      C   python                           2797MiB |\n",
      "|    6   N/A  N/A   3823451      C   python                           7431MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
