{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86876e4a-ae69-4ac6-8ce9-a7e3ae7d437e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76810fd8-a9ba-4daf-b972-762aaef5dd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9efc75ea-5fc9-4a40-9c08-c00203b7199f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !watch -n 0.5 nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a0eb504-1e95-48af-aeb2-e8734870b0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0\n",
      "11.3\n",
      "8201\n",
      "0\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)  # 1.9.1+cu111\n",
    "print(torch.version.cuda)  # 11.1\n",
    "print(torch.backends.cudnn.version())  # 8005\n",
    "print(torch.cuda.current_device())  # 0\n",
    "print(torch.cuda.is_available())  # TRUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "179dcc0a-000e-4009-b7d6-57a8bae7d4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"True\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54e46c7b-8d4b-42b8-ae9c-6c7d43bb1d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Aug  2 20:53:44 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:18:00.0 Off |                  N/A |\n",
      "| 31%   41C    P2    51W / 250W |   1816MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  On   | 00000000:3B:00.0 Off |                  N/A |\n",
      "| 28%   29C    P8    13W / 250W |      3MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce ...  On   | 00000000:86:00.0 Off |                  N/A |\n",
      "| 28%   30C    P8    13W / 250W |      1MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce ...  On   | 00000000:AF:00.0 Off |                  N/A |\n",
      "| 43%   78C    P2   253W / 250W |   5597MiB / 11019MiB |     57%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A   1425217      C   python3                          1813MiB |\n",
      "|    3   N/A  N/A   2369742      C   python                           2797MiB |\n",
      "|    3   N/A  N/A   3678694      C   python                           2797MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "499ba33b-26e7-4629-a398-9d8c098f2f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 16% |\n",
      "|  1 |  0% |  0% |\n",
      "|  2 |  0% |  0% |\n",
      "|  3 | 58% | 51% |\n",
      "GPU Usage after emptying the cache\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 16% |\n",
      "|  1 |  0% |  1% |\n",
      "|  2 |  0% |  0% |\n",
      "|  3 | 64% | 51% |\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from GPUtil import showUtilization as gpu_usage\n",
    "from numba import cuda\n",
    "\n",
    "def free_gpu_cache():\n",
    "    print(\"Initial GPU Usage\")\n",
    "    gpu_usage()                             \n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    cuda.select_device(0)\n",
    "    cuda.close()\n",
    "    cuda.select_device(0)\n",
    "\n",
    "    print(\"GPU Usage after emptying the cache\")\n",
    "    gpu_usage()\n",
    "\n",
    "free_gpu_cache()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1286125-81ef-4e56-85f0-229bd7ebf8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"TD_dataset_clean.csv\" , index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c10dfb05-8aa2-46af-befb-db7f66dc57c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_clean</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>look for min file instead</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>as an extension of 78</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bountysourceplugin want to back this issue pla...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>our grunt script is out of control its current...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jshint is dropping stylerelated support it see...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127686</th>\n",
       "      <td>ci is no more ok all i could see right now is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127687</th>\n",
       "      <td>agentwebfragment 打开其他网址没问题，打开httpsopenapialipa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127688</th>\n",
       "      <td>this wouldnt quite be the same as an installpa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127689</th>\n",
       "      <td>oh no a bug it happens thanks for reporting an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127690</th>\n",
       "      <td>hi all describe the bug pyforcefieldconstraint...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127691 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               text_clean  label\n",
       "0                               look for min file instead      1\n",
       "1                                   as an extension of 78      1\n",
       "2       bountysourceplugin want to back this issue pla...      1\n",
       "3       our grunt script is out of control its current...      1\n",
       "4       jshint is dropping stylerelated support it see...      1\n",
       "...                                                   ...    ...\n",
       "127686  ci is no more ok all i could see right now is ...      0\n",
       "127687  agentwebfragment 打开其他网址没问题，打开httpsopenapialipa...      0\n",
       "127688  this wouldnt quite be the same as an installpa...      0\n",
       "127689  oh no a bug it happens thanks for reporting an...      0\n",
       "127690  hi all describe the bug pyforcefieldconstraint...      0\n",
       "\n",
       "[127691 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08a259d6-0d8f-439e-b45e-53d60afbed0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.21.0\n",
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import transformers\n",
    "\n",
    "print(transformers.__version__)\n",
    "print(datasets.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb4abf33-6386-47ab-b3ea-e6e84790f8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset, Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdc4e718-8d69-4005-bd0d-5a83196c08bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9a30cdd-8023-40f7-bc45-aa12db307910",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_id = \"microsoft/deberta-v3-base\"\n",
    "\n",
    "epochs = 5\n",
    "num_labels = 2 \n",
    "learning_rate = 2e-5\n",
    "train_batch_size = 16\n",
    "eval_batch_size = 32\n",
    "save_strategy = \"no\"\n",
    "save_steps = 500\n",
    "logging_steps = 100\n",
    "\n",
    "model_dir = \"./model1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf0f3ec8-7b2d-4163-9166-7ac43efac73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def train_validate_test_split(df, train_percent=.6, validate_percent=.2, seed=None):\n",
    "    np.random.seed(seed)\n",
    "    perm = np.random.permutation(df.index)\n",
    "    m = len(df.index)\n",
    "    train_end = int(train_percent * m)\n",
    "    validate_end = int(validate_percent * m) + train_end\n",
    "    train = df.iloc[perm[:train_end]]\n",
    "    validate = df.iloc[perm[train_end:validate_end]]\n",
    "    test = df.iloc[perm[validate_end:]]\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3182ddb-061d-4334-9ee9-6a2ee328e53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "522f2754-39ac-4b3f-96b9-d37936544f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7671d782-78ba-4b00-99b1-960f9c0fbf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns= [\"index\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "661accab-d00f-42b3-a6c1-856f6498ca38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_clean</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>look for min file instead</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>as an extension of 78</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bountysourceplugin want to back this issue pla...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>our grunt script is out of control its current...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jshint is dropping stylerelated support it see...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127671</th>\n",
       "      <td>ci is no more ok all i could see right now is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127672</th>\n",
       "      <td>agentwebfragment 打开其他网址没问题，打开httpsopenapialipa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127673</th>\n",
       "      <td>this wouldnt quite be the same as an installpa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127674</th>\n",
       "      <td>oh no a bug it happens thanks for reporting an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127675</th>\n",
       "      <td>hi all describe the bug pyforcefieldconstraint...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127676 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               text_clean  label\n",
       "0                               look for min file instead      1\n",
       "1                                   as an extension of 78      1\n",
       "2       bountysourceplugin want to back this issue pla...      1\n",
       "3       our grunt script is out of control its current...      1\n",
       "4       jshint is dropping stylerelated support it see...      1\n",
       "...                                                   ...    ...\n",
       "127671  ci is no more ok all i could see right now is ...      0\n",
       "127672  agentwebfragment 打开其他网址没问题，打开httpsopenapialipa...      0\n",
       "127673  this wouldnt quite be the same as an installpa...      0\n",
       "127674  oh no a bug it happens thanks for reporting an...      0\n",
       "127675  hi all describe the bug pyforcefieldconstraint...      0\n",
       "\n",
       "[127676 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c66a9eba-a3be-4bd2-8871-e0a969c89c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train , validate , test = train_validate_test_split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87e4139a-da82-48ea-82d0-3c108fbc568c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train.set_index(\"label\" , inplace = True)\n",
    "validate.set_index(\"label\" , inplace = True)\n",
    "test.set_index(\"label\" , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4e5eaef-189e-4aef-b599-b6fd9e3ed985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>description of the problem when i try to perfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>descriptive summary hyrax 302 makes rails 526 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the logout function is not revoking user auth ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>as a service provider i need the service to pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what would you like to be added the name of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>there seems to be a few issues with where erro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mobile scroll and mobile scrollto are the only...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acceptance test labels for 16 17 and 18 appear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>steps to reproduce 1 install the desktop app f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pouryamansouri ای پی ای ایجاد حجره روی برنچ ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25536 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text_clean\n",
       "label                                                   \n",
       "0      description of the problem when i try to perfo...\n",
       "1      descriptive summary hyrax 302 makes rails 526 ...\n",
       "0      the logout function is not revoking user auth ...\n",
       "0      as a service provider i need the service to pe...\n",
       "0      what would you like to be added the name of th...\n",
       "...                                                  ...\n",
       "0      there seems to be a few issues with where erro...\n",
       "1      mobile scroll and mobile scrollto are the only...\n",
       "0      acceptance test labels for 16 17 and 18 appear...\n",
       "0      steps to reproduce 1 install the desktop app f...\n",
       "0      pouryamansouri ای پی ای ایجاد حجره روی برنچ ma...\n",
       "\n",
       "[25536 rows x 1 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572b19a0-5e59-414f-86a7-5a27b94febd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3e6f629-d8fb-4537-a2cd-37d23581c84c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['text_clean', 'label'],\n",
       "        num_rows: 25536\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['text_clean', 'label'],\n",
       "        num_rows: 76605\n",
       "    })\n",
       "    validate: Dataset({\n",
       "        features: ['text_clean', 'label'],\n",
       "        num_rows: 25535\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tds = Dataset.from_pandas(train)\n",
    "vds = Dataset.from_pandas(validate)\n",
    "testds = Dataset.from_pandas(test)\n",
    "\n",
    "ds = DatasetDict()\n",
    "\n",
    "ds[\"test\"] = testds\n",
    "ds[\"train\"] = tds\n",
    "ds[\"validate\"] = vds\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d8fc417-44e4-4f8a-9148-7cd4c2a068c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ds[\"train\"]\n",
    "valid_dataset = ds[\"validate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a570f5e-3312-4005-8fa3-dc6787abe6cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text_clean': '问题描述 单元素的数组json序列化的时候，没有中括号；后面直接导致解析端用fastjon反序列化的时候，直接报格式错误 环境信息 请填写以下信息： os信息： eg：centos 842105 4core 310ghz 16 gb jdk信息： eg：hotspot jdk 1703 版本信息：eg：fastjson2 204 重现步骤 如何操作可以重现该问题： 一些框架在序列化的时候，如果是单元素的集合，直接就是省去了中括号后面直接导致解析端用fastjon2反序列化的时候，直接报格式错误 name zhangsan books 西游记 name zhangsan books 西游记红楼梦 1 使用 xxxxxx 方法 2 输入 数据 3 出现 错误 java 可在此输入示例代码 data public class student private string name private liststring books public class jsonmain public static void mainstring args try string str name zhangsan books 西游记 student json1 jsonobjectparseobjectstr studentclass systemoutprintlnjson1 json1 catch exception e eprintstacktrace finally string str2 name zhangsan books 西游记 红楼梦 student json2 jsonobjectparseobjectstr2 studentclass systemoutprintlnjson2 json2 期待的正确结果 对您期望发生的结果进行清晰简洁的描述。 希望fastjson能支持解析单元素数组场景下不含有中括号，也能解析成功 相关日志输出 请复制并粘贴任何相关的日志输出。 comalibabafastjson2jsonexception json format error at comalibabafastjson2readerfieldreaderliststrmethodreadfieldvaluefieldreaderliststrmethodjava83 at comalibabafastjson2readerobjectreader2readobjectobjectreader2java241 at comalibabafastjson2jsonparseobjectjsonjava258 at comalibabafastjson2jsonobjectparseobjectjsonobjectjava1717 附加信息 如果你还有其他需要提供的信息，可以在这里填写（可以提供截图、视频等）。',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"train\"][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ddc5dc57-4dd0-4426-a7bc-1879db379711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "89217897-605d-4e42-91a7-5ecb60e78be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2ForSequenceClassification: ['lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.bias', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.classifier.bias']\n",
      "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/itf-fi-ml/home/karths/.local/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py:434: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(base_model_id, num_labels=num_labels)\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id)\n",
    "# optim = torch.optim.Adam(model.parameters(), lr=5e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "39754469-d2c2-412b-b0de-daa3110a397b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91237a97eb5a4c33a7cf4dd884868122",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92e633eed3574bc987e0364e2612824c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " def tokenize(batch):\n",
    "    return tokenizer(batch[\"text_clean\"], padding=\"max_length\",max_length=256, truncation=True)\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=True, batch_size=len(train_dataset))\n",
    "valid_dataset = valid_dataset.map(tokenize, batched=True, batch_size=len(valid_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "21396d25-3e29-4a36-acf7-d5aea28268fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=model_dir,\n",
    "    num_train_epochs=epochs,\n",
    "    per_device_train_batch_size=train_batch_size,\n",
    "    per_device_eval_batch_size=eval_batch_size,\n",
    "    save_strategy=save_strategy,\n",
    "    save_steps=save_steps,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=learning_rate,\n",
    "    logging_steps=logging_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8dbc3b2f-d33a-4795-9aa9-9fea6270662c",
   "metadata": {},
   "outputs": [],
   "source": [
    " trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59719f9c-d921-45dc-9be9-f53c431da859",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text_clean. If text_clean are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/itf-fi-ml/home/karths/.local/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 76605\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 23940\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23940' max='23940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23940/23940 6:34:44, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.327000</td>\n",
       "      <td>0.293458</td>\n",
       "      <td>0.880674</td>\n",
       "      <td>[0.89224458 0.86631861]</td>\n",
       "      <td>[0.89214993 0.86643265]</td>\n",
       "      <td>[0.89233925 0.8662046 ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.229500</td>\n",
       "      <td>0.345603</td>\n",
       "      <td>0.887057</td>\n",
       "      <td>[0.8954163  0.87724525]</td>\n",
       "      <td>[0.91866954 0.85193452]</td>\n",
       "      <td>[0.87331117 0.90410598]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.165800</td>\n",
       "      <td>0.356749</td>\n",
       "      <td>0.888310</td>\n",
       "      <td>[0.90264218 0.86903012]</td>\n",
       "      <td>[0.87227024 0.91173637]</td>\n",
       "      <td>[0.93520549 0.83014564]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.125500</td>\n",
       "      <td>0.453026</td>\n",
       "      <td>0.892148</td>\n",
       "      <td>[0.90211132 0.87992675]</td>\n",
       "      <td>[0.90662285 0.87458832]</td>\n",
       "      <td>[0.89764448 0.88533076]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.087700</td>\n",
       "      <td>0.502955</td>\n",
       "      <td>0.891600</td>\n",
       "      <td>[0.90212164 0.87854322]</td>\n",
       "      <td>[0.90193028 0.87877458]</td>\n",
       "      <td>[0.90231308 0.87831198]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text_clean. If text_clean are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25535\n",
      "  Batch size = 32\n",
      "Trainer is attempting to log a value of \"[0.89224458 0.86631861]\" of type <class 'numpy.ndarray'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.89214993 0.86643265]\" of type <class 'numpy.ndarray'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.89233925 0.8662046 ]\" of type <class 'numpy.ndarray'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text_clean. If text_clean are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25535\n",
      "  Batch size = 32\n",
      "Trainer is attempting to log a value of \"[0.8954163  0.87724525]\" of type <class 'numpy.ndarray'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.91866954 0.85193452]\" of type <class 'numpy.ndarray'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.87331117 0.90410598]\" of type <class 'numpy.ndarray'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text_clean. If text_clean are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25535\n",
      "  Batch size = 32\n",
      "Trainer is attempting to log a value of \"[0.90264218 0.86903012]\" of type <class 'numpy.ndarray'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.87227024 0.91173637]\" of type <class 'numpy.ndarray'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.93520549 0.83014564]\" of type <class 'numpy.ndarray'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text_clean. If text_clean are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25535\n",
      "  Batch size = 32\n",
      "Trainer is attempting to log a value of \"[0.90211132 0.87992675]\" of type <class 'numpy.ndarray'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.90662285 0.87458832]\" of type <class 'numpy.ndarray'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.89764448 0.88533076]\" of type <class 'numpy.ndarray'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text_clean. If text_clean are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25535\n",
      "  Batch size = 32\n",
      "Trainer is attempting to log a value of \"[0.90212164 0.87854322]\" of type <class 'numpy.ndarray'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.90193028 0.87877458]\" of type <class 'numpy.ndarray'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.90231308 0.87831198]\" of type <class 'numpy.ndarray'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=23940, training_loss=0.20204814871650192, metrics={'train_runtime': 23689.098, 'train_samples_per_second': 16.169, 'train_steps_per_second': 1.011, 'total_flos': 5.03899596589824e+16, 'train_loss': 0.20204814871650192, 'epoch': 5.0})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8941fbc3-a492-4d7b-9595-fabd30c36b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text_clean. If text_clean are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25535\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='798' max='798' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [798/798 10:44]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"[0.90212164 0.87854322]\" of type <class 'numpy.ndarray'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.90193028 0.87877458]\" of type <class 'numpy.ndarray'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"[0.90231308 0.87831198]\" of type <class 'numpy.ndarray'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    }
   ],
   "source": [
    "eval_result = trainer.evaluate(eval_dataset=valid_dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "17d67e68-4290-4655-a2a5-08565b230495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 5.0\n",
      "\n",
      "eval_accuracy = 0.8915997650283924\n",
      "\n",
      "eval_f1 = [0.90212164 0.87854322]\n",
      "\n",
      "eval_loss = 0.5029550194740295\n",
      "\n",
      "eval_precision = [0.90193028 0.87877458]\n",
      "\n",
      "eval_recall = [0.90231308 0.87831198]\n",
      "\n",
      "eval_runtime = 645.1756\n",
      "\n",
      "eval_samples_per_second = 39.578\n",
      "\n",
      "eval_steps_per_second = 1.237\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, value in sorted(eval_result.items()):\n",
    "    print(f\"{key} = {value}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a61e2e8f-651f-448e-a3b5-92923f5d869c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./model1_local\n",
      "Configuration saved in ./model1_local/config.json\n",
      "Model weights saved in ./model1_local/pytorch_model.bin\n",
      "tokenizer config file saved in ./model1_local/tokenizer_config.json\n",
      "Special tokens file saved in ./model1_local/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(model_dir + \"_local\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1cce0269-0feb-4332-aefe-b5457dbbf1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in ./model1_local_tokenizer/tokenizer_config.json\n",
      "Special tokens file saved in ./model1_local_tokenizer/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./model1_local_tokenizer/tokenizer_config.json',\n",
       " './model1_local_tokenizer/special_tokens_map.json',\n",
       " './model1_local_tokenizer/spm.model',\n",
       " './model1_local_tokenizer/added_tokens.json',\n",
       " './model1_local_tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(model_dir + \"_local_tokenizer\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76341c2-252f-4063-892f-b5ff1a0f5858",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ec71f53a-5b3a-4573-8576-4f2f909a07e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./model1_local/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"./model1_local\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaV2ForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.21.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading configuration file ./model1_local/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"./model1_local\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaV2ForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.21.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading weights file ./model1_local/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n",
      "\n",
      "All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at ./model1_local.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n",
      "loading file ./model1_local/spm.model\n",
      "loading file ./model1_local/tokenizer.json\n",
      "loading file ./model1_local/added_tokens.json\n",
      "loading file ./model1_local/special_tokens_map.json\n",
      "loading file ./model1_local/tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    " from transformers import pipeline\n",
    "    \n",
    "classifier = pipeline(\"text-classification\", model=\"./model1_local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8ee67b83-09fd-4866-ac34-87f17f3047d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_1', 'score': 0.9999406337738037}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"descriptive summary hyrax 302 makes rails 526 support official and rails 526 includes a security update for polymorphicpath which is a method used in all link generation across rails linkto urlfor etc all these methods no longer support string parameters which must be converted to symbols this is a problem in 526 and 5246 our current 525 is unaffected and upgrading may see problems on random pages we should check through the application for calls to polymorphicpath urlfor linkto and any other link generating methods you can think of all hyrax links should be fixed in 302 then we can safely update to hyrax 302 and rails 526 expected behavior all links on site call their generation method with symbols or objects not strings hyrax 302 rails 526 related work blocked 1578 from going to 302 accessibility concerns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "940cccf0-9772-4806-a5ec-3440b9f51d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.9995662569999695}]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"description of the problem when i try to perform file upload in sut via the browsers running in docker the file upload popup is not opening and neither accepts any files causing scripts to fail browser and version safari operating system ran on docker webdrivermanager version v503\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5357e725-8bb1-452b-bc82-51745ec51dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.9972280859947205}]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"after user sing up the email must be confirmed prepare a goodlooking email template develop a be to send this template after user registration develop an endpoint to check confirmation token develop a fe page with confirmation status create a cron to check accounts which havent confirmed an email and remove them\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1fc39f0c-e95e-4f91-aca1-6b54f2be21df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text_clean': ['current layer always reported as last layer eg 150150',\n",
       "  'after user sing up the email must be confirmed prepare a goodlooking email template develop a be to send this template after user registration develop an endpoint to check confirmation token develop a fe page with confirmation status create a cron to check accounts which havent confirmed an email and remove them',\n",
       "  'environment server prod version id or medalcreator url 40httpsmedalcreatorunisantechapiv1versions40 architecture clientserver app version 1012210001212 describe the bug missing mandatory id key for nodes 7648 answer null value null 7773 answer null value 7782 answer null value null 7786 answer null value null 7838 answer null value null 7955 answer null value null 7956 answer null value null 8110 answer null value null 8468 answer null value null 10082 answer null value 7837 answer null value null 7955 answer null value null 7956 answer null value null',\n",
       "  'kibana version 830 elasticsearch version 830 server os version elastic cloud and on premises docker images original install method eg download page yum from source etc originally found in onpremises install from official docker images later confirmed also on elastic cloud instances describe the bug were unable to execute requests with query parameters for ex get catnodesv from console when you execute those request with curl directly querying es server everything works as expected when we remove query string everything executes properly just confirmed this issue is present also on elastic cloud v83 instances maybe this bug was introduced with this enhancement httpswwwelasticcoguideenkibanacurrentwhatsnewhtmlhighlights83console dev tools console now supports sending requests to kibana apis prepend any kibana api endpoint with kbn and send the request steps to reproduce 1 open dev tools console 2 try to execute following request get catnodesv 3 later try this yes i know it is missing some required properties post ingestpipelinesimulateverbose expected behavior for the first case expected proper response as taken from 823 cloud instance ip heappercent rampercent cpu load1m load5m load15m noderole master name 10425103 39 59 22 156 119 115 himrst instance0000000001 10424147 32 83 0 261 192 177 mv tiebreaker0000000002 10425225 36 59 13 168 130 118 himrst instance0000000000 instead we get json error rootcause type illegalargumentexception reason request catnodes contains unrecognized parameter v type illegalargumentexception reason request catnodes contains unrecognized parameter v status 400 in the second case you would expect some error about missing property json error rootcause type parseexception reason pipeline required property is missing propertyname pipeline type parseexception reason pipeline required property is missing propertyname pipeline status 400 instead youll get json error incorrect http method for uri ingest2fpipeline2fsimulateverboseprettytrue and method post allowed get put head delete status 405'],\n",
       " 'label': [0, 0, 0, 0]}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testds[5:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94bbafa-6752-490b-aef4-b28198a8de20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9780e1c8-59ef-4f94-8cc1-51de47297499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text_clean', 'label'],\n",
       "    num_rows: 25536\n",
       "})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d59f3784-1228-4e19-8d7b-584fa2c8218b",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "304ff834-53ae-41c3-aa97-d29aee93d888",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7afece32-fd8d-49a3-a017-5ad5bd0ff505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Tue Aug  2 11:52:53 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0 Off |                  N/A |\n",
      "| 22%   25C    P8    15W / 250W |      1MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  On   | 00000000:23:00.0 Off |                  N/A |\n",
      "| 22%   25C    P8     7W / 250W |  11008MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce ...  On   | 00000000:41:00.0 Off |                  N/A |\n",
      "| 22%   32C    P2    57W / 250W |   1688MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce ...  On   | 00000000:61:00.0 Off |                  N/A |\n",
      "| 25%   48C    P2   218W / 250W |   6748MiB / 11019MiB |     82%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA GeForce ...  On   | 00000000:81:00.0 Off |                  N/A |\n",
      "| 22%   27C    P8    23W / 250W |      1MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA GeForce ...  On   | 00000000:A1:00.0 Off |                  N/A |\n",
      "| 23%   45C    P2   190W / 250W |   2802MiB / 11019MiB |     29%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA GeForce ...  On   | 00000000:C1:00.0 Off |                  N/A |\n",
      "| 22%   33C    P2    76W / 250W |   7436MiB / 11019MiB |     38%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA GeForce ...  On   | 00000000:E1:00.0 Off |                  N/A |\n",
      "| 22%   25C    P8    31W / 250W |      1MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    1   N/A  N/A   3331446      C   ...core-11.2.0/bin/python3.9    11005MiB |\n",
      "|    2   N/A  N/A   4185318      C   python3                          1681MiB |\n",
      "|    3   N/A  N/A   2449359      C   python                           2797MiB |\n",
      "|    3   N/A  N/A   2463154      C   python                           2797MiB |\n",
      "|    3   N/A  N/A   3258387      C   python                           1149MiB |\n",
      "|    5   N/A  N/A   1587331      C   python                           2797MiB |\n",
      "|    6   N/A  N/A   3823451      C   python                           7431MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
