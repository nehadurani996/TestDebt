{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86876e4a-ae69-4ac6-8ce9-a7e3ae7d437e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76810fd8-a9ba-4daf-b972-762aaef5dd16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9efc75ea-5fc9-4a40-9c08-c00203b7199f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !watch -n 0.5 nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a0eb504-1e95-48af-aeb2-e8734870b0b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n",
      "11.8\n",
      "8700\n",
      "0\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)  # 1.9.1+cu111\n",
    "print(torch.version.cuda)  # 11.1\n",
    "print(torch.backends.cudnn.version())  # 8005\n",
    "print(torch.cuda.current_device())  # 0\n",
    "print(torch.cuda.is_available())  # TRUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "179dcc0a-000e-4009-b7d6-57a8bae7d4d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"False\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54e46c7b-8d4b-42b8-ae9c-6c7d43bb1d63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov 22 17:01:36 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 530.30.02              Driver Version: 530.30.02    CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2080 Ti      On | 00000000:01:00.0 Off |                  N/A |\n",
      "| 37%   52C    P2               83W / 250W|   2521MiB / 11264MiB |     28%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 2080 Ti      On | 00000000:23:00.0 Off |                  N/A |\n",
      "| 44%   73C    P2              249W / 250W|  10431MiB / 11264MiB |    100%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce RTX 2080 Ti      On | 00000000:41:00.0 Off |                  N/A |\n",
      "| 45%   73C    P2              244W / 250W|  10431MiB / 11264MiB |     99%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce RTX 2080 Ti      On | 00000000:61:00.0 Off |                  N/A |\n",
      "| 38%   64C    P2              240W / 250W|  10431MiB / 11264MiB |    100%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA GeForce RTX 2080 Ti      On | 00000000:81:00.0 Off |                  N/A |\n",
      "| 25%   45C    P2               51W / 250W|   1307MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA GeForce RTX 2080 Ti      On | 00000000:A1:00.0 Off |                  N/A |\n",
      "| 41%   68C    P2              234W / 250W|   3641MiB / 11264MiB |     88%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA GeForce RTX 2080 Ti      On | 00000000:C1:00.0 Off |                  N/A |\n",
      "| 41%   68C    P2              220W / 250W|   3641MiB / 11264MiB |     86%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA GeForce RTX 2080 Ti      On | 00000000:E1:00.0 Off |                  N/A |\n",
      "| 41%   67C    P2              237W / 250W|  10431MiB / 11264MiB |    100%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A   2841103      C   python                                     1418MiB |\n",
      "|    0   N/A  N/A   2894266      C   .../home/krimhau/miniconda3/bin/python      154MiB |\n",
      "|    1   N/A  N/A   1390515      C   ...ml/home/limeng/torch_env/bin/python    10424MiB |\n",
      "|    2   N/A  N/A   1390516      C   ...ml/home/limeng/torch_env/bin/python    10424MiB |\n",
      "|    3   N/A  N/A   1390517      C   ...ml/home/limeng/torch_env/bin/python    10424MiB |\n",
      "|    5   N/A  N/A   2022916      C   python3                                    3636MiB |\n",
      "|    6   N/A  N/A   2025669      C   python3                                    3636MiB |\n",
      "|    7   N/A  N/A   1390518      C   ...ml/home/limeng/torch_env/bin/python    10424MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "499ba33b-26e7-4629-a398-9d8c098f2f92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial GPU Usage\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 |  26% | 22% |\n",
      "|  1 | 100% | 93% |\n",
      "|  2 | 100% | 93% |\n",
      "|  3 | 100% | 93% |\n",
      "|  4 |   0% | 12% |\n",
      "|  5 |  10% | 32% |\n",
      "|  6 |  94% | 32% |\n",
      "|  7 | 100% | 93% |\n",
      "GPU Usage after emptying the cache\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 |  26% | 22% |\n",
      "|  1 | 100% | 93% |\n",
      "|  2 | 100% | 93% |\n",
      "|  3 | 100% | 93% |\n",
      "|  4 |   0% | 13% |\n",
      "|  5 |  10% | 32% |\n",
      "|  6 |  95% | 32% |\n",
      "|  7 | 100% | 93% |\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from GPUtil import showUtilization as gpu_usage\n",
    "from numba import cuda\n",
    "\n",
    "def free_gpu_cache():\n",
    "    print(\"Initial GPU Usage\")\n",
    "    gpu_usage()                             \n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    cuda.select_device(0)\n",
    "    cuda.close()\n",
    "    cuda.select_device(0)\n",
    "\n",
    "    print(\"GPU Usage after emptying the cache\")\n",
    "    gpu_usage()\n",
    "\n",
    "free_gpu_cache()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1286125-81ef-4e56-85f0-229bd7ebf8a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"TD_dataset_clean.csv\" , index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c10dfb05-8aa2-46af-befb-db7f66dc57c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_clean</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>look for min file instead</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>as an extension of 78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bountysourceplugin want to back this issue pla...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>our grunt script is out of control its current...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jshint is dropping stylerelated support it see...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470600</th>\n",
       "      <td>你的功能请求是否与问题有关？ 希望可以为每日任务 困难图 增加次数选择功能。目前我的解决办法...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470601</th>\n",
       "      <td>rootlocalhost lsblk name majmin rm size ro typ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470602</th>\n",
       "      <td>env gpu rtx1060 os ubuntu1804 docker cuda vers...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470603</th>\n",
       "      <td>env gpu 1080ti os ubuntu1804 cuda version114 t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470604</th>\n",
       "      <td>like what does yc stand for</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>470605 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               text_clean  label\n",
       "0                               look for min file instead      0\n",
       "1                                   as an extension of 78      0\n",
       "2       bountysourceplugin want to back this issue pla...      0\n",
       "3       our grunt script is out of control its current...      0\n",
       "4       jshint is dropping stylerelated support it see...      0\n",
       "...                                                   ...    ...\n",
       "470600  你的功能请求是否与问题有关？ 希望可以为每日任务 困难图 增加次数选择功能。目前我的解决办法...      0\n",
       "470601  rootlocalhost lsblk name majmin rm size ro typ...      0\n",
       "470602  env gpu rtx1060 os ubuntu1804 docker cuda vers...      0\n",
       "470603  env gpu 1080ti os ubuntu1804 cuda version114 t...      0\n",
       "470604                        like what does yc stand for      0\n",
       "\n",
       "[470605 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08a259d6-0d8f-439e-b45e-53d60afbed0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.33.2\n",
      "2.14.5\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import transformers\n",
    "\n",
    "print(transformers.__version__)\n",
    "print(datasets.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb4abf33-6386-47ab-b3ea-e6e84790f8cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset, Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdc4e718-8d69-4005-bd0d-5a83196c08bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9a30cdd-8023-40f7-bc45-aa12db307910",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_model_id = \"distilbert-base-uncased\"\n",
    "\n",
    "epochs = 5\n",
    "num_labels = 2 \n",
    "learning_rate = 5e-5\n",
    "train_batch_size = 16\n",
    "eval_batch_size = 32\n",
    "save_strategy = \"no\"\n",
    "save_steps = 500\n",
    "logging_steps = 100\n",
    "model_dir = \"./model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf0f3ec8-7b2d-4163-9166-7ac43efac73d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def train_validate_test_split(df, train_percent=.6, validate_percent=.2, seed=None):\n",
    "    np.random.seed(seed)\n",
    "    perm = np.random.permutation(df.index)\n",
    "    m = len(df.index)\n",
    "    train_end = int(train_percent * m)\n",
    "    validate_end = int(validate_percent * m) + train_end\n",
    "    train = df.iloc[perm[:train_end]]\n",
    "    validate = df.iloc[perm[train_end:validate_end]]\n",
    "    test = df.iloc[perm[validate_end:]]\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b5f0b4",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3182ddb-061d-4334-9ee9-6a2ee328e53f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "522f2754-39ac-4b3f-96b9-d37936544f00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7671d782-78ba-4b00-99b1-960f9c0fbf91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.drop(columns= [\"index\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "661accab-d00f-42b3-a6c1-856f6498ca38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_clean</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>look for min file instead</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>as an extension of 78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bountysourceplugin want to back this issue pla...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>our grunt script is out of control its current...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jshint is dropping stylerelated support it see...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470556</th>\n",
       "      <td>你的功能请求是否与问题有关？ 希望可以为每日任务 困难图 增加次数选择功能。目前我的解决办法...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470557</th>\n",
       "      <td>rootlocalhost lsblk name majmin rm size ro typ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470558</th>\n",
       "      <td>env gpu rtx1060 os ubuntu1804 docker cuda vers...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470559</th>\n",
       "      <td>env gpu 1080ti os ubuntu1804 cuda version114 t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470560</th>\n",
       "      <td>like what does yc stand for</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>470561 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               text_clean  label\n",
       "0                               look for min file instead      0\n",
       "1                                   as an extension of 78      0\n",
       "2       bountysourceplugin want to back this issue pla...      0\n",
       "3       our grunt script is out of control its current...      0\n",
       "4       jshint is dropping stylerelated support it see...      0\n",
       "...                                                   ...    ...\n",
       "470556  你的功能请求是否与问题有关？ 希望可以为每日任务 困难图 增加次数选择功能。目前我的解决办法...      0\n",
       "470557  rootlocalhost lsblk name majmin rm size ro typ...      0\n",
       "470558  env gpu rtx1060 os ubuntu1804 docker cuda vers...      0\n",
       "470559  env gpu 1080ti os ubuntu1804 cuda version114 t...      0\n",
       "470560                        like what does yc stand for      0\n",
       "\n",
       "[470561 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c66a9eba-a3be-4bd2-8871-e0a969c89c2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train , validate , test = train_validate_test_split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87e4139a-da82-48ea-82d0-3c108fbc568c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "train.set_index(\"label\" , inplace = True)\n",
    "validate.set_index(\"label\" , inplace = True)\n",
    "test.set_index(\"label\" , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4e5eaef-189e-4aef-b599-b6fd9e3ed985",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user story as a vha digital media web manager ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>imagehttpsuserimagesgithubusercontentcom899234...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>required information operating system windows ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>without cleaning up erischains manually a ton ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>example imagehttpsuserimagesgithubusercontentc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in the large table element of srcstylespagetem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>steps to reproduce düngerstreuer bredal k165 a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is your feature request related to a problem p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aktuell werden nur tests durchgeführt und dere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>環境 os 例 windows 版 バージョン 例 300alpha59 バグの詳細 修正値...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94113 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text_clean\n",
       "label                                                   \n",
       "0      user story as a vha digital media web manager ...\n",
       "0      imagehttpsuserimagesgithubusercontentcom899234...\n",
       "0      required information operating system windows ...\n",
       "0      without cleaning up erischains manually a ton ...\n",
       "0      example imagehttpsuserimagesgithubusercontentc...\n",
       "...                                                  ...\n",
       "0      in the large table element of srcstylespagetem...\n",
       "0      steps to reproduce düngerstreuer bredal k165 a...\n",
       "0      is your feature request related to a problem p...\n",
       "0      aktuell werden nur tests durchgeführt und dere...\n",
       "0      環境 os 例 windows 版 バージョン 例 300alpha59 バグの詳細 修正値...\n",
       "\n",
       "[94113 rows x 1 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3e6f629-d8fb-4537-a2cd-37d23581c84c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['text_clean', 'label'],\n",
       "        num_rows: 94113\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['text_clean', 'label'],\n",
       "        num_rows: 282336\n",
       "    })\n",
       "    validate: Dataset({\n",
       "        features: ['text_clean', 'label'],\n",
       "        num_rows: 94112\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tds = Dataset.from_pandas(train)\n",
    "vds = Dataset.from_pandas(validate)\n",
    "testds = Dataset.from_pandas(test)\n",
    "\n",
    "ds = DatasetDict()\n",
    "\n",
    "ds[\"test\"] = testds\n",
    "ds[\"train\"] = tds\n",
    "ds[\"validate\"] = vds\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d8fc417-44e4-4f8a-9148-7cd4c2a068c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = ds[\"train\"]\n",
    "valid_dataset = ds[\"validate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a570f5e-3312-4005-8fa3-dc6787abe6cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text_clean': 'describe the bug when i execute a command in dm with bot it doesnt reply to reproduce 1 go to dm with the bot 2 execute a slash command 4 see error expected behavior should return reply with default styling environment please complete the following information commit 5a56f35e07ec3e5c98495ddf81cb2905da2eeebc branch main additional context this issue started after adding guild based embed configurations',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"train\"][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ddc5dc57-4dd0-4426-a7bc-1879db379711",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89217897-605d-4e42-91a7-5ecb60e78be3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(base_model_id, num_labels=num_labels)\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id)\n",
    "# optim = torch.optim.Adam(model.parameters(), lr=5e-5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620c6f33",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff9691b",
   "metadata": {},
   "source": [
    "    Character tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "faf02213",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T', 'o', 'k', 'e', 'n', 'i', 'z', 'i', 'n', 'g', ' ', 't', 'e', 'x', 't', ' ', 'i', 's', ' ', 'a', ' ', 'c', 'o', 'r', 'e', ' ', 't', 'a', 's', 'k', ' ', 'o', 'f', ' ', 'N', 'L', 'P', '.']\n"
     ]
    }
   ],
   "source": [
    "text = \"Tokenizing text is a core task of NLP.\"\n",
    "tokenized_text = list(text)\n",
    "print(tokenized_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4366068a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, '.': 1, 'L': 2, 'N': 3, 'P': 4, 'T': 5, 'a': 6, 'c': 7, 'e': 8, 'f': 9, 'g': 10, 'i': 11, 'k': 12, 'n': 13, 'o': 14, 'r': 15, 's': 16, 't': 17, 'x': 18, 'z': 19}\n"
     ]
    }
   ],
   "source": [
    "token2idx = {ch: idx for idx, ch in enumerate(sorted(set(tokenized_text)))}\n",
    "print(token2idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2cd16d12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 14, 12, 8, 13, 11, 19, 11, 13, 10, 0, 17, 8, 18, 17, 0, 11, 16, 0, 6, 0, 7, 14, 15, 8, 0, 17, 6, 16, 12, 0, 14, 9, 0, 3, 2, 4, 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_ids = [token2idx[token] for token in tokenized_text]\n",
    "print(input_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f4efcebb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([38, 20])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "input_ids = torch.tensor(input_ids)\n",
    "one_hot_encodings = F.one_hot(input_ids, num_classes=len(token2idx))\n",
    "one_hot_encodings.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a26a1ee7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: T\n",
      "Tensor index: 5\n",
      "One-hot: tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Token: {tokenized_text[0]}\")\n",
    "print(f\"Tensor index: {input_ids[0]}\")\n",
    "print(f\"One-hot: {one_hot_encodings[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb42615e",
   "metadata": {},
   "source": [
    "    Word Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b556f9e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tokenizing', 'text', 'is', 'a', 'core', 'task', 'of', 'NLP.']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenized_text = text.split()\n",
    "print(tokenized_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2137d64d",
   "metadata": {},
   "source": [
    "    Subword Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2dcd5a33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_ckpt = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e7d5c155",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 19204, 6026, 3793, 2003, 1037, 4563, 4708, 1997, 17953, 2361, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "encoded_text = tokenizer(text)\n",
    "print(encoded_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "db2d465f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'token', '##izing', 'text', 'is', 'a', 'core', 'task', 'of', 'nl', '##p', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(encoded_text.input_ids)\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b0a21c13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] tokenizing text is a core task of nlp. [SEP]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.convert_tokens_to_string(tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6aa159f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tokenizer.vocab_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "170755b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tokenizer.model_max_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "663acfe8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_ids', 'attention_mask']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_input_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dc6a3397",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Special Token</th>\n",
       "      <td>[PAD]</td>\n",
       "      <td>[UNK]</td>\n",
       "      <td>[CLS]</td>\n",
       "      <td>[SEP]</td>\n",
       "      <td>[MASK]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Special Token ID</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>101</td>\n",
       "      <td>102</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0      1      2      3       4\n",
       "Special Token     [PAD]  [UNK]  [CLS]  [SEP]  [MASK]\n",
       "Special Token ID      0    100    101    102     103"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#hide_input\n",
    "tokens2ids = list(zip(tokenizer.all_special_tokens, tokenizer.all_special_ids))\n",
    "data = sorted(tokens2ids, key=lambda x: x[-1])\n",
    "df = pd.DataFrame(data, columns=[\"Special Token\", \"Special Token ID\"])\n",
    "df.T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ecfa49",
   "metadata": {},
   "source": [
    "    Tokenizing the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "39754469-d2c2-412b-b0de-daa3110a397b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b7ae9f2be9f4c608fa69658a0aa32be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/282336 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3fb0a00dc0b4216b7397609aad879ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/94112 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text_clean\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=True, batch_size=len(train_dataset))\n",
    "valid_dataset = valid_dataset.map(tokenize, batched=True, batch_size=len(valid_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d956940",
   "metadata": {},
   "source": [
    "## Training a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86ec95b",
   "metadata": {},
   "source": [
    "Models like DistilBERT are pretrained to predict masked words in a sequence of text. However, we can't use these language models directly for text classification; we need to modify them slightly. To understand what modifications are necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "68a7880c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_model_id = \"distilbert-base-uncased\"\n",
    "\n",
    "epochs = 2\n",
    "num_labels = 2 \n",
    "learning_rate = 5e-5\n",
    "train_batch_size = 16\n",
    "eval_batch_size = 32\n",
    "save_strategy = \"no\"\n",
    "save_steps = 500\n",
    "logging_steps = 100\n",
    "model_dir = \"./model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "21396d25-3e29-4a36-acf7-d5aea28268fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=model_dir,\n",
    "    num_train_epochs=epochs,\n",
    "    per_device_train_batch_size=train_batch_size,\n",
    "    per_device_eval_batch_size=eval_batch_size,\n",
    "    save_strategy=save_strategy,\n",
    "    save_steps=save_steps,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=learning_rate,\n",
    "    logging_steps=logging_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8dbc3b2f-d33a-4795-9aa9-9fea6270662c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "abe3d720-84f3-4f3f-b79c-69355e83b9e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "59719f9c-d921-45dc-9be9-f53c431da859",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='35292' max='35292' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35292/35292 3:40:19, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.039300</td>\n",
       "      <td>0.034709</td>\n",
       "      <td>0.994464</td>\n",
       "      <td>[0.99722434 0.        ]</td>\n",
       "      <td>[0.99446404 0.        ]</td>\n",
       "      <td>[1. 0.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.045700</td>\n",
       "      <td>0.035852</td>\n",
       "      <td>0.994464</td>\n",
       "      <td>[0.99722434 0.        ]</td>\n",
       "      <td>[0.99446404 0.        ]</td>\n",
       "      <td>[1. 0.]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/itf-fi-ml/home/nehad/.conda/envs/dl/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/itf-fi-ml/home/nehad/.conda/envs/dl/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=35292, training_loss=0.034037989419522394, metrics={'train_runtime': 13224.0559, 'train_samples_per_second': 42.7, 'train_steps_per_second': 2.669, 'total_flos': 7.480063093388083e+16, 'train_loss': 0.034037989419522394, 'epoch': 2.0})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8941fbc3-a492-4d7b-9595-fabd30c36b16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2941' max='2941' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2941/2941 10:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/itf-fi-ml/home/nehad/.conda/envs/dl/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "eval_result = trainer.evaluate(eval_dataset=valid_dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a259219c-a1b7-44eb-b1b9-191b7032033a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 2.0\n",
      "\n",
      "eval_accuracy = 0.9944640428425705\n",
      "\n",
      "eval_f1 = [0.99722434 0.        ]\n",
      "\n",
      "eval_loss = 0.03585215285420418\n",
      "\n",
      "eval_precision = [0.99446404 0.        ]\n",
      "\n",
      "eval_recall = [1. 0.]\n",
      "\n",
      "eval_runtime = 604.2653\n",
      "\n",
      "eval_samples_per_second = 155.746\n",
      "\n",
      "eval_steps_per_second = 4.867\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, value in sorted(eval_result.items()):\n",
    "    print(f\"{key} = {value}\\n\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b76341c2-252f-4063-892f-b5ff1a0f5858",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.save_model(model_dir + \"_local\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ec71f53a-5b3a-4573-8576-4f2f909a07e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "    \n",
    "classifier = pipeline(\"text-classification\", model=\"./model_local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "51e36054",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8ee67b83-09fd-4866-ac34-87f17f3047d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.9976814985275269}]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"Woo hoo almost done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77583b84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9780e1c8-59ef-4f94-8cc1-51de47297499",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d80e9dcf-3fe3-4f3e-9d44-f62537aadf1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d59f3784-1228-4e19-8d7b-584fa2c8218b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "304ff834-53ae-41c3-aa97-d29aee93d888",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7afece32-fd8d-49a3-a017-5ad5bd0ff505",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov 22 21:00:06 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 530.30.02              Driver Version: 530.30.02    CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2080 Ti      On | 00000000:01:00.0 Off |                  N/A |\n",
      "| 43%   70C    P2              249W / 250W|   3311MiB / 11264MiB |     95%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 2080 Ti      On | 00000000:23:00.0 Off |                  N/A |\n",
      "| 38%   65C    P2              218W / 250W|  10767MiB / 11264MiB |    100%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce RTX 2080 Ti      On | 00000000:41:00.0 Off |                  N/A |\n",
      "| 36%   63C    P2              114W / 250W|  10767MiB / 11264MiB |    100%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce RTX 2080 Ti      On | 00000000:61:00.0 Off |                  N/A |\n",
      "| 32%   56C    P2              212W / 250W|  10767MiB / 11264MiB |    100%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA GeForce RTX 2080 Ti      On | 00000000:81:00.0 Off |                  N/A |\n",
      "| 42%   59C    P2               59W / 250W|   2849MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA GeForce RTX 2080 Ti      On | 00000000:A1:00.0 Off |                  N/A |\n",
      "| 43%   70C    P2              225W / 250W|  10757MiB / 11264MiB |     41%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA GeForce RTX 2080 Ti      On | 00000000:C1:00.0 Off |                  N/A |\n",
      "| 40%   66C    P2              239W / 250W|   3975MiB / 11264MiB |     93%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA GeForce RTX 2080 Ti      On | 00000000:E1:00.0 Off |                  N/A |\n",
      "| 35%   60C    P2              183W / 250W|  10767MiB / 11264MiB |    100%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A   2894266      C   .../home/krimhau/miniconda3/bin/python      536MiB |\n",
      "|    0   N/A  N/A   3140524      C   ...dinger/2023-3/internal/bin/gdesmond      448MiB |\n",
      "|    0   N/A  N/A   3374830      C   python                                     1414MiB |\n",
      "|    1   N/A  N/A   1390515      C   ...ml/home/limeng/torch_env/bin/python    10424MiB |\n",
      "|    1   N/A  N/A   2894266      C   .../home/krimhau/miniconda3/bin/python      334MiB |\n",
      "|    2   N/A  N/A   1390516      C   ...ml/home/limeng/torch_env/bin/python    10424MiB |\n",
      "|    2   N/A  N/A   2894266      C   .../home/krimhau/miniconda3/bin/python      334MiB |\n",
      "|    3   N/A  N/A   1390517      C   ...ml/home/limeng/torch_env/bin/python    10424MiB |\n",
      "|    3   N/A  N/A   2894266      C   .../home/krimhau/miniconda3/bin/python      334MiB |\n",
      "|    4   N/A  N/A   2894266      C   .../home/krimhau/miniconda3/bin/python      334MiB |\n",
      "|    4   N/A  N/A   2897932      C   ...ome/nehad/.conda/envs/dl/bin/python     1208MiB |\n",
      "|    5   N/A  N/A   2022916      C   python3                                    3636MiB |\n",
      "|    5   N/A  N/A   2894266      C   .../home/krimhau/miniconda3/bin/python      334MiB |\n",
      "|    5   N/A  N/A   3039488      C   python3                                    6782MiB |\n",
      "|    6   N/A  N/A   2025669      C   python3                                    3636MiB |\n",
      "|    6   N/A  N/A   2894266      C   .../home/krimhau/miniconda3/bin/python      334MiB |\n",
      "|    7   N/A  N/A   1390518      C   ...ml/home/limeng/torch_env/bin/python    10424MiB |\n",
      "|    7   N/A  N/A   2894266      C   .../home/krimhau/miniconda3/bin/python      334MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
